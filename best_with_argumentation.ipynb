{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60a16556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import GPUtil\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import os\n",
    "from torch_geometric.data import Dataset, download_url\n",
    "from torch_geometric.loader import DataLoader\n",
    "import pandas as pd\n",
    "from performance import performances_val\n",
    "from PIL import Image\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "from torch_geometric.nn.norm import BatchNorm\n",
    "from torch_geometric.data import Data\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.nn import ChebConv, GraphSAGE,GraphUNet ,TransformerConv\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "seed = 1378\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "landmark_colors = np.load(\"landmark_colors.npy\")\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_list=[]\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(np.expand_dims(landmark_colors,axis=1))  \n",
    "for x in landmark_colors:\n",
    "    one_hot_list.append(enc.transform([[x]]).toarray()[0])\n",
    "one_hot_arr  = np.array(one_hot_list)\n",
    "one_hot_arr = torch.FloatTensor(one_hot_arr)\n",
    "class landmark_dataset(Dataset):\n",
    "    def __init__(self, info_list, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(None, transform, pre_transform, pre_filter)\n",
    "        \n",
    "        self.graphs = pd.read_csv(info_list, delimiter=\",\", header=None)\n",
    "\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def get(self, idx):\n",
    "        \n",
    "        graph_path = self.graphs.iloc[idx]\n",
    "        graph_path = graph_path[0]\n",
    "        \n",
    "        \n",
    "        data = torch.load(graph_path)\n",
    "        #data.x =data.x.t()\n",
    "        return data \n",
    "class landmark_dataset_train(Dataset):\n",
    "    def __init__(self, info_list, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(None, transform, pre_transform, pre_filter)\n",
    "        \n",
    "        self.graphs = pd.read_csv(info_list, delimiter=\",\", header=None)\n",
    "\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def get(self, idx):\n",
    "        \n",
    "        graph_path = self.graphs.iloc[idx]\n",
    "        graph_path = graph_path[0]\n",
    "        \n",
    "        data = torch.load(graph_path)\n",
    "        \n",
    " \n",
    "        \n",
    "        domain_name = graph_path.split(\"/\")[-4]\n",
    "        \n",
    "            \n",
    "        if domain_name == \"MSU_MFSD\" :\n",
    "            \n",
    "            #domain_label = torch.FloatTensor([[1,0,0]])\n",
    "            domain_label = 1\n",
    "            \n",
    "        elif domain_name == \"Replay_attack_dataset\" :\n",
    "            \n",
    "            #domain_label = torch.FloatTensor([[0,1,0]])\n",
    "            domain_label = 0\n",
    "            \n",
    "        elif domain_name == \"oulu\" :\n",
    "            \n",
    "            #domain_label = torch.FloatTensor([[0,0,1]])\n",
    "            domain_label = 2\n",
    "        else :\n",
    "            print(graph_path,domain_name )\n",
    "            raise \"error\"\n",
    "            \n",
    "        \n",
    "        data = Data(x=data.x, edge_index=data.edge_index,y =data.y,data = domain_label,y_node = one_hot_arr)\n",
    "\n",
    "        #data.x =data.x.t()\n",
    "        return data \n",
    "train_dataset = landmark_dataset_train(\"/home/hassan-hossein/single_image_graph_face_anti_spoofing/train/graph_train_O_M_I.txt\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True,num_workers=16,pin_memory=True)\n",
    "\n",
    "test_dataset = landmark_dataset(\"/home/hassan-hossein/single_image_graph_face_anti_spoofing/train/graph_test_C.txt\")\n",
    "test_loader = DataLoader(test_dataset, batch_size=64,num_workers=16)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "# فرض کنید که داده‌های ورودی شما یک توالی از ۶۸۰ ویژگی دارد.\n",
    "#sequence_length = 128\n",
    "#feature_dim = 4  # هر ویژگی تک‌بعدی است\n",
    "\n",
    "# نمونه داده ورودی (تعداد نمونه‌ها × طول توالی × بعد ویژگی)\n",
    "#inputs = torch.rand(32, sequence_length, feature_dim)  # 32 نمونه با 680 ویژگی تک‌بعدی\n",
    "# تعریف یک لایه ترنسفورمر انکودر\n",
    "class SimpleTransformer(nn.Module):\n",
    "    def __init__(self, embed_dim, num_layers, nhead,n_out):\n",
    "        super(SimpleTransformer, self).__init__()\n",
    "        self.linear = nn.Linear(4, embed_dim)  # افزایش بعد ویژگی‌ها\n",
    "        self.encoder_layer = TransformerEncoderLayer(d_model=embed_dim, nhead=nhead)\n",
    "        self.transformer_encoder = TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(128 * embed_dim, n_out)  # فرضا 10 کلاس خروجی داریم\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)  # تغییر بعد ویژگی‌ها\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.view(x.size(0), -1)  # فشرده‌سازی به یک بردار برای طبقه‌بندی\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# # ایجاد مدل و ارسال ورودی\n",
    "# # model = SimpleTransformer(embed_dim=embed_dim, num_layers=2, nhead=4)\n",
    "# # output = model(inputs)\n",
    "\n",
    "# #print(output.shape)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "# فرض کنید که داده‌های ورودی شما یک توالی از ۶۸۰ ویژگی دارد.\n",
    "sequence_length = 128\n",
    "feature_dim = 1  # هر ویژگی تک‌بعدی است\n",
    "\n",
    "# نمونه داده ورودی (تعداد نمونه‌ها × طول توالی × بعد ویژگی)\n",
    "#inputs = torch.rand(32, sequence_length, feature_dim)  # 32 نمونه با 680 ویژگی تک‌بعدی\n",
    "\n",
    "# تعریف یک لایه ترنسفورمر انکودر\n",
    "class SimpleTransformer_2(nn.Module):\n",
    "    def __init__(self, embed_dim, num_layers, nhead):\n",
    "        super(SimpleTransformer_2, self).__init__()\n",
    "        self.linear = nn.Linear(feature_dim, embed_dim)  # افزایش بعد ویژگی‌ها\n",
    "        self.encoder_layer = TransformerEncoderLayer(d_model=embed_dim, nhead=nhead)\n",
    "        self.transformer_encoder = TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(sequence_length * embed_dim, 7)  # فرضا 10 کلاس خروجی داریم\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)  # تغییر بعد ویژگی‌ها\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.view(x.size(0), -1)  # فشرده‌سازی به یک بردار برای طبقه‌بندی\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# # ایجاد مدل و ارسال ورودی\n",
    "# # model = SimpleTransformer(embed_dim=embed_dim, num_layers=2, nhead=4)\n",
    "# # output = model(inputs)\n",
    "\n",
    "# #print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b4c8ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = torch.tensor([61989, 15549, 136334], dtype=torch.float32)\n",
    "\n",
    "# محاسبه وزن‌ها به صورت معکوس تعداد نمونه‌ها\n",
    "class_weights = 1.0 / class_counts\n",
    "\n",
    "# نرمال‌سازی وزن‌ها به طوری که مجموع آن‌ها یک شود\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "\n",
    "class_weights  = class_weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f502c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1838, 0.7327, 0.0836], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd95adbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): ChebConv(640, 128, K=2, normalization=sym)\n",
      "  (conv2): ChebConv(128, 128, K=2, normalization=sym)\n",
      "  (conv3): ChebConv(128, 128, K=2, normalization=sym)\n",
      "  (conv4): ChebConv(128, 128, K=2, normalization=sym)\n",
      "  (conv5): ChebConv(256, 128, K=2, normalization=sym)\n",
      "  (conv6): ChebConv(128, 128, K=2, normalization=sym)\n",
      "  (conv7): ChebConv(128, 128, K=2, normalization=sym)\n",
      "  (conv8): ChebConv(128, 128, K=2, normalization=sym)\n",
      "  (lin): SimpleTransformer(\n",
      "    (linear): Linear(in_features=4, out_features=8, bias=True)\n",
      "    (encoder_layer): TransformerEncoderLayer(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "      )\n",
      "      (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "      (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Linear(in_features=1024, out_features=1, bias=True)\n",
      "  )\n",
      "  (drop_1): RandomNodeDropout()\n",
      "  (drop_2): RandomNodeDropout()\n",
      "  (drop_3): RandomNodeDropout()\n",
      "  (drop_4): RandomNodeDropout()\n",
      "  (drop_5): RandomNodeDropout()\n",
      "  (drop_6): RandomNodeDropout()\n",
      "  (b1): BatchNorm(128)\n",
      "  (b2): BatchNorm(128)\n",
      "  (b3): BatchNorm(128)\n",
      "  (b4): BatchNorm(128)\n",
      "  (b5): BatchNorm(128)\n",
      "  (b6): BatchNorm(128)\n",
      "  (b7): BatchNorm(128)\n",
      "  (dis): Discriminator(\n",
      "    (conv1): GraphSAGE(128, 128, num_layers=2)\n",
      "    (conv2): GraphSAGE(128, 128, num_layers=2)\n",
      "    (conv3): GraphSAGE(128, 128, num_layers=2)\n",
      "    (conv4): GraphSAGE(128, 128, num_layers=2)\n",
      "    (drop_1): RandomNodeDropout()\n",
      "    (drop_2): RandomNodeDropout()\n",
      "    (grl_layer): GRL()\n",
      "    (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (conv1_node_class): GraphSAGE(128, 128, num_layers=2)\n",
      "  (conv2_node_class): GraphSAGE(128, 128, num_layers=2)\n",
      "  (lin_node_class): SimpleTransformer_2(\n",
      "    (linear): Linear(in_features=1, out_features=64, bias=True)\n",
      "    (encoder_layer): TransformerEncoderLayer(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "      (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (6): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (7): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (8): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (9): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Linear(in_features=8192, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class RandomNodeDropout(nn.Module):\n",
    "    def __init__(self, drop_prob=0.3):\n",
    "        super(RandomNodeDropout, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x, enabled=True):\n",
    "        if not self.training or not enabled:\n",
    "            return x\n",
    "        \n",
    "        num_rows = x.size(0)\n",
    "        mask = torch.rand(num_rows, device=x.device) > self.drop_prob\n",
    "        mask = mask.float().unsqueeze(1).expand_as(x)\n",
    "        x = x * mask\n",
    "        \n",
    "        return x\n",
    "\n",
    "soft = torch.nn.Softmax(dim=1)\n",
    "\n",
    "num_domain = 3\n",
    "class GRL(nn.Module):\n",
    "\n",
    "    def __init__(self, max_iter):\n",
    "        super(GRL, self).__init__()\n",
    "        self.iter_num = 0\n",
    "        self.alpha = 10\n",
    "        self.low = 0.0\n",
    "        self.high = 1.0\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.iter_num += 1\n",
    "        return input * 1.0\n",
    "\n",
    "    def backward(self, gradOutput):\n",
    "        coeff = np.float(2.0 * (self.high - self.low) / (1.0 + np.exp(-self.alpha * self.iter_num / self.max_iter))\n",
    "                         - (self.high - self.low) + self.low)\n",
    "        return -coeff*10* gradOutput\n",
    "\n",
    "num_node  =train_dataset.num_node_features\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self,hidden_channels ,max_iter):\n",
    "        super(Discriminator, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GraphSAGE(hidden_channels, hidden_channels,2,dropout=0.5)\n",
    "        self.conv2 = GraphSAGE(hidden_channels, hidden_channels,2,dropout=0.5)\n",
    "        self.conv3 = GraphSAGE(hidden_channels, hidden_channels,2,dropout=0.5)\n",
    "        self.conv4 = GraphSAGE(hidden_channels, hidden_channels,2,dropout=0.5)\n",
    "        self.drop_1 = RandomNodeDropout(drop_prob=0.3)\n",
    "        self.drop_2 = RandomNodeDropout(drop_prob=0.3)\n",
    "        self.grl_layer = GRL(max_iter)\n",
    "        self.fc2 = nn.Linear(hidden_channels, num_domain)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch,drop_en):\n",
    "        #print(\"graph fea :\",graph_level_feature.shape ,edge_index.shape )\n",
    "        \n",
    "        x = self.grl_layer(x)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.drop_1(x,drop_en)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.drop_2(x,drop_en)\n",
    "        \n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "         \n",
    "        return x \n",
    "\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels,max_iter=4000):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = ChebConv(num_node, hidden_channels,2)\n",
    "        self.conv2 = ChebConv(hidden_channels, hidden_channels,2)\n",
    "        self.conv3 = ChebConv(hidden_channels, hidden_channels,2)\n",
    "        self.conv4 = ChebConv(hidden_channels, hidden_channels,2)\n",
    "        self.conv5 = ChebConv(hidden_channels*2, hidden_channels,2)\n",
    "        self.conv6 = ChebConv(hidden_channels, hidden_channels,2)\n",
    "        self.conv7 = ChebConv(hidden_channels, hidden_channels,2)\n",
    "        self.conv8 = ChebConv(hidden_channels, hidden_channels,2)\n",
    "        self.lin = SimpleTransformer(8,5,8,1)\n",
    "        \n",
    "        self.drop_1 = RandomNodeDropout(drop_prob=0.3)\n",
    "        self.drop_2 = RandomNodeDropout(drop_prob=0.3)\n",
    "        self.drop_3 = RandomNodeDropout(drop_prob=0.3)\n",
    "        self.drop_4 = RandomNodeDropout(drop_prob=0.3)\n",
    "        self.drop_5 = RandomNodeDropout(drop_prob=0.3)\n",
    "        self.drop_6 = RandomNodeDropout(drop_prob=0.3)\n",
    "        \n",
    "        \n",
    "        self.b1 = BatchNorm(hidden_channels)\n",
    "        self.b2 = BatchNorm(hidden_channels)\n",
    "        self.b3 = BatchNorm(hidden_channels)\n",
    "        self.b4 = BatchNorm(hidden_channels)\n",
    "        self.b5 = BatchNorm(hidden_channels)\n",
    "        self.b6 = BatchNorm(hidden_channels)\n",
    "        self.b7 = BatchNorm(hidden_channels)\n",
    "        \n",
    "        self.dis = Discriminator(hidden_channels,max_iter)\n",
    "        \n",
    "        self.conv1_node_class = GraphSAGE(hidden_channels, hidden_channels,2,dropout=0.5)\n",
    "        \n",
    "        self.conv2_node_class = GraphSAGE(hidden_channels, hidden_channels,2,dropout=0.5)\n",
    "        \n",
    "        self.lin_node_class = SimpleTransformer_2(64,10,8)\n",
    "        \n",
    "\n",
    "        \n",
    "        #self.tcn = Simple1DCNN()\n",
    "        \n",
    "    def forward(self, x, edge_index, batch,drop_en,index_arr):\n",
    "        #print(\"graph fea :\",graph_level_feature.shape ,edge_index.shape )\n",
    "        \n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x  = self.b1(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        #x = self.drop_1(x,drop_en)\n",
    "        \n",
    "        \n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x  = self.b2(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        #x = self.drop_2(x,drop_en)\n",
    "                \n",
    "        dicriminator = x\n",
    "        \n",
    "        x_1 = global_mean_pool(x, batch)\n",
    "        \n",
    "        x = self.conv3(x, edge_index)\n",
    "        x  = self.b3(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = self.drop_3(x,drop_en)\n",
    "        \n",
    "        x_3 = global_mean_pool(x, batch)\n",
    "        \n",
    "        \n",
    "        x = self.conv4(x, edge_index)\n",
    "        x  = self.b4(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = self.drop_4(x,drop_en)\n",
    "        \n",
    "        \n",
    "        x = torch.cat((x,dicriminator),dim=1) #skip connection\n",
    "        \n",
    "        x = self.conv5(x, edge_index)\n",
    "        x  = self.b5(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = self.drop_5(x,drop_en)\n",
    "        \n",
    "        x_5 = global_mean_pool(x, batch)\n",
    "        \n",
    "        x = self.conv6(x, edge_index)\n",
    "        x  = self.b6(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = self.drop_6(x,drop_en)\n",
    "        \n",
    "        x = self.conv7(x, edge_index)\n",
    "        x  = self.b7(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        \n",
    "        x = self.conv8(x, edge_index)\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "        \n",
    "        x = torch.stack([x,x_1,x_5,x_3],dim=2)\n",
    "        \n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        \n",
    "        #x = torch.unsqueeze(x,2)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        x = self.lin(x)\n",
    "        \n",
    "        x= x.sigmoid()\n",
    "        \n",
    "        \n",
    "        node_class_hidden = self.conv1_node_class(dicriminator,edge_index)\n",
    "        node_class_hidden = node_class_hidden.relu()\n",
    "        \n",
    "        node_class_hidden = self.conv2_node_class(node_class_hidden,edge_index)\n",
    "        node_class_hidden = node_class_hidden.relu()\n",
    "        \n",
    "        #print(index_arr.shape , node_class_hidden.shape)\n",
    "        \n",
    "        node_class_hidden = node_class_hidden[index_arr]\n",
    "        \n",
    "        #print(node_class_hidden.shape)\n",
    "        node_class_hidden = torch.unsqueeze(node_class_hidden, dim=2)\n",
    "        \n",
    "        node_pre = self.lin_node_class(node_class_hidden)\n",
    "        \n",
    "            \n",
    "        #print(\"hiiii :\" , dicriminator.shape)\n",
    "        dis_invariant = self.dis(dicriminator,edge_index,batch,drop_en)\n",
    "        \n",
    "        return x ,dis_invariant ,node_pre\n",
    "\n",
    "model = GCN(hidden_channels=128).to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "def check_folder(log_dir):\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    return log_dir\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "#class_weights = torch.tensor([w1, w2, w3, ...])  # Replace with actual weights\n",
    "criterion= nn.BCELoss()\n",
    "criterion_node_class=  torch.nn.CrossEntropyLoss()\n",
    "criterion_2 = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    losses_adv_loss=0\n",
    "    losses_loss_cls=0\n",
    "    total_loss = 0\n",
    "    losses_node_cls_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}', unit='batch')\n",
    "    for graph in progress_bar:  # Iterate in batches over the training dataset.\n",
    "        graph = graph.to(device)  # Move data to the device\n",
    "        \n",
    "        drop_en = bool(np.random.binomial(1, 0.5))\n",
    "        \n",
    "        if graph.x.shape[0] < 29952 :\n",
    "            \n",
    "            if graph.x.shape[0] < 64:\n",
    "            \n",
    "                index_arr = torch.randint(0, int(graph.x.shape[0]), (int(graph.x.shape[0]),)).to(device)\n",
    "            else :\n",
    "                \n",
    "                index_arr = torch.randint(0, int(graph.x.shape[0]), (64,)).to(device)\n",
    "        else :\n",
    "                \n",
    "            index_arr = torch.randint(0, 29952, (64,)).to(device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        out,domain_invariant,node_pre = model(graph.x, graph.edge_index, graph.batch,drop_en,index_arr)  # Perform a single forward pass.\n",
    "        \n",
    "        adv_loss = criterion_2(domain_invariant, graph.data)\n",
    "        \n",
    "        node_cls_loss = criterion_node_class(node_pre.squeeze(),graph.y_node.float()[index_arr])\n",
    "        #print(out.shape , graph.y.long().shape)\n",
    "        loss_cls = criterion(out.squeeze(), graph.y.float())  # Compute the loss.\n",
    "        \n",
    "        loss_all = 0.1* adv_loss + 0.8*loss_cls + 0.1*node_cls_loss\n",
    "        loss_all.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "        total_loss = loss_all + total_loss\n",
    "        losses_adv_loss = adv_loss + losses_adv_loss\n",
    "        losses_loss_cls = loss_cls + losses_loss_cls\n",
    "        losses_node_cls_loss = node_cls_loss + losses_node_cls_loss\n",
    "\n",
    "\n",
    "    print(\"/////////////////////////\")\n",
    "    print(\"adverserial loss : \" ,losses_adv_loss/len(train_loader.dataset))  \n",
    "    print(\"classification loss : \" , losses_loss_cls/len(train_loader.dataset))\n",
    "    print(\"classification node loss : \" , losses_node_cls_loss/len(train_loader.dataset))\n",
    "    print(\"total loss : \" ,total_loss/len(train_loader.dataset) )\n",
    "    print(\"////////////////////////////////////\")\n",
    "def test(loader,epoch):\n",
    "    score_path = os.path.join(\"/home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores\", \"epoch_{}\".format(epoch+1))\n",
    "    check_folder(score_path)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        scores_list = []\n",
    "\n",
    "        correct = 0\n",
    "        s= 0\n",
    "        progress_bar = tqdm(loader, desc=f'Epoch {epoch+1}', unit='batch')\n",
    "        for graph in progress_bar:  # Iterate in batches over the training/test dataset.\n",
    "            if graph.x.shape[0] < 29952 :\n",
    "\n",
    "                if graph.x.shape[0] < 64:\n",
    "\n",
    "                    index_arr = torch.randint(0, int(graph.x.shape[0]), (int(graph.x.shape[0]),)).to(device)\n",
    "                else :\n",
    "\n",
    "                    index_arr = torch.randint(0, int(graph.x.shape[0]), (64,)).to(device)\n",
    "            else :\n",
    "\n",
    "                index_arr = torch.randint(0, 29952, (64,)).to(device)\n",
    "                \n",
    "            graph = graph.to(device)  # Move data to the device\n",
    "            logit,_ ,_= model(graph.x, graph.edge_index, graph.batch,False,index_arr)\n",
    "            live_label = graph.y.float()\n",
    "            for i in range(len(logit)):\n",
    "                        scores_list.append(\"{} {}\\n\".format(logit[i].item(), live_label[i].item()))\n",
    "  # Check against ground-truth labels.\n",
    "    map_score_val_filename = os.path.join(score_path, \"score.txt\")\n",
    "    with open(map_score_val_filename, 'w') as file:\n",
    "                file.writelines(scores_list)\n",
    "    print(\"score: write test scores to {}\".format(map_score_val_filename))\n",
    "    test_ACC, fpr, FRR, HTER, auc_test, test_err, tpr = performances_val(map_score_val_filename)\n",
    "    print(\"epoch:{:d}, test:  val_ACC={:.4f}, HTER={:.4f}, AUC={:.4f}, val_err={:.4f}, ACC={:.4f}, TPR={:.4f}\".format(\n",
    "        epoch + 1, test_ACC, HTER, auc_test, test_err, test_ACC, tpr))  \n",
    "    return auc_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21041009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|███████████████████████████| 3342/3342 [07:33<00:00,  7.36batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████████████| 349/349 [00:54<00:00,  6.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_1/score.txt\n",
      "epoch:1, test:  val_ACC=0.7850, HTER=0.2151, AUC=0.8716, val_err=0.2151, ACC=0.7850, TPR=0.5643\n",
      "improve acc .. .. ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|███████████████████████████| 3342/3342 [08:45<00:00,  6.37batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(7.8190e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(4.5084e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████████████████████████████| 349/349 [00:52<00:00,  6.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_2/score.txt\n",
      "epoch:2, test:  val_ACC=0.7456, HTER=0.2544, AUC=0.8282, val_err=0.2545, ACC=0.7456, TPR=0.5003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|███████████████████████████| 3342/3342 [08:36<00:00,  6.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(4.7079e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.2483e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████████████████████████████| 349/349 [00:52<00:00,  6.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_3/score.txt\n",
      "epoch:3, test:  val_ACC=0.8189, HTER=0.1811, AUC=0.8874, val_err=0.1811, ACC=0.8189, TPR=0.7079\n",
      "improve acc .. .. ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|███████████████████████████| 3342/3342 [08:35<00:00,  6.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(3.4634e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(2.8766e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|█████████████████████████████| 349/349 [00:53<00:00,  6.52batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_4/score.txt\n",
      "epoch:4, test:  val_ACC=0.8052, HTER=0.1948, AUC=0.8871, val_err=0.1948, ACC=0.8052, TPR=0.6398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|███████████████████████████| 3342/3342 [08:38<00:00,  6.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.5390e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(2.5840e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|█████████████████████████████| 349/349 [00:52<00:00,  6.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_5/score.txt\n",
      "epoch:5, test:  val_ACC=0.7790, HTER=0.2210, AUC=0.8545, val_err=0.2210, ACC=0.7790, TPR=0.4593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|███████████████████████████| 3342/3342 [08:40<00:00,  6.42batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(3.2763e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(2.2850e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|█████████████████████████████| 349/349 [00:51<00:00,  6.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_6/score.txt\n",
      "epoch:6, test:  val_ACC=0.7876, HTER=0.2125, AUC=0.8660, val_err=0.2125, ACC=0.7876, TPR=0.5096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|███████████████████████████| 3342/3342 [08:33<00:00,  6.51batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(8.9686e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(2.2465e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|█████████████████████████████| 349/349 [00:52<00:00,  6.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_7/score.txt\n",
      "epoch:7, test:  val_ACC=0.8289, HTER=0.1711, AUC=0.9018, val_err=0.1711, ACC=0.8289, TPR=0.6756\n",
      "improve acc .. .. ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|███████████████████████████| 3342/3342 [08:38<00:00,  6.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(5.3678e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.1051e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(9.0044e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|█████████████████████████████| 349/349 [00:52<00:00,  6.59batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_8/score.txt\n",
      "epoch:8, test:  val_ACC=0.8736, HTER=0.1264, AUC=0.9379, val_err=0.1265, ACC=0.8736, TPR=0.7966\n",
      "improve acc .. .. ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|███████████████████████████| 3342/3342 [08:34<00:00,  6.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(2.9745e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.6167e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(7.8045e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|█████████████████████████████| 349/349 [00:50<00:00,  6.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_9/score.txt\n",
      "epoch:9, test:  val_ACC=0.8158, HTER=0.1843, AUC=0.8892, val_err=0.1842, ACC=0.8158, TPR=0.6001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████████████████████| 3342/3342 [08:34<00:00,  6.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(2.6418e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.0929e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(6.1710e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|████████████████████████████| 349/349 [00:51<00:00,  6.80batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_10/score.txt\n",
      "epoch:10, test:  val_ACC=0.8519, HTER=0.1481, AUC=0.9275, val_err=0.1481, ACC=0.8519, TPR=0.7597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████████████████████| 3342/3342 [08:30<00:00,  6.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(5.4036e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.6465e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(5.5921e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|████████████████████████████| 349/349 [00:53<00:00,  6.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_11/score.txt\n",
      "epoch:11, test:  val_ACC=0.7514, HTER=0.2550, AUC=0.7966, val_err=0.2556, ACC=0.7514, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████████████████████| 3342/3342 [08:32<00:00,  6.52batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(5.4868e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.3078e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(4.6050e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|████████████████████████████| 349/349 [00:54<00:00,  6.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_12/score.txt\n",
      "epoch:12, test:  val_ACC=0.8497, HTER=0.1503, AUC=0.9165, val_err=0.1503, ACC=0.8497, TPR=0.6469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████████████████████| 3342/3342 [08:36<00:00,  6.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.6217e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(7.1265e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(3.7595e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|████████████████████████████| 349/349 [00:50<00:00,  6.85batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_13/score.txt\n",
      "epoch:13, test:  val_ACC=0.9516, HTER=0.2065, AUC=0.8332, val_err=0.2126, ACC=0.9516, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████████████████████| 3342/3342 [08:34<00:00,  6.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(3.7492e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(9.2243e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(3.8041e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████████████████████████████| 349/349 [00:52<00:00,  6.69batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_14/score.txt\n",
      "epoch:14, test:  val_ACC=0.8286, HTER=0.1715, AUC=0.9115, val_err=0.1715, ACC=0.8286, TPR=0.6654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████████████████████| 3342/3342 [08:36<00:00,  6.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.0985e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.3153e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(3.4801e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|████████████████████████████| 349/349 [00:51<00:00,  6.77batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_15/score.txt\n",
      "epoch:15, test:  val_ACC=0.8384, HTER=0.1616, AUC=0.9156, val_err=0.1616, ACC=0.8384, TPR=0.6665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████████████████████| 3342/3342 [08:28<00:00,  6.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(6.4544e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.3089e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(3.2844e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|████████████████████████████| 349/349 [00:51<00:00,  6.71batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_16/score.txt\n",
      "epoch:16, test:  val_ACC=0.7563, HTER=0.2437, AUC=0.8382, val_err=0.2437, ACC=0.7563, TPR=0.3613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████████████████████| 3342/3342 [08:39<00:00,  6.43batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.0644e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(9.1103e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(2.8012e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|████████████████████████████| 349/349 [00:51<00:00,  6.71batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_17/score.txt\n",
      "epoch:17, test:  val_ACC=0.8215, HTER=0.1785, AUC=0.8886, val_err=0.1785, ACC=0.8215, TPR=0.6918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████████████████████| 3342/3342 [08:34<00:00,  6.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.6129e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(6.7188e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(2.6296e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|████████████████████████████| 349/349 [00:53<00:00,  6.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_18/score.txt\n",
      "epoch:18, test:  val_ACC=0.7997, HTER=0.2002, AUC=0.8796, val_err=0.2003, ACC=0.7997, TPR=0.5272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████████████████████| 3342/3342 [08:35<00:00,  6.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(5.2465e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(7.7198e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(2.2576e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|████████████████████████████| 349/349 [00:57<00:00,  6.12batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_19/score.txt\n",
      "epoch:19, test:  val_ACC=0.7770, HTER=0.2234, AUC=0.8279, val_err=0.2235, ACC=0.7770, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████████████████████| 3342/3342 [08:38<00:00,  6.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(4.1800e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(2.8228e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(1.8224e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|████████████████████████████| 349/349 [00:53<00:00,  6.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_20/score.txt\n",
      "epoch:20, test:  val_ACC=0.8772, HTER=0.1228, AUC=0.9315, val_err=0.1228, ACC=0.8772, TPR=0.7844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████████████████████| 3342/3342 [08:43<00:00,  6.39batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(2.2142e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(8.5517e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(2.1321e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|████████████████████████████| 349/349 [00:51<00:00,  6.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_21/score.txt\n",
      "epoch:21, test:  val_ACC=0.8741, HTER=0.1260, AUC=0.9347, val_err=0.1260, ACC=0.8741, TPR=0.7912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████████████████████| 3342/3342 [08:34<00:00,  6.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.8142e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.1099e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(2.3378e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|████████████████████████████| 349/349 [00:53<00:00,  6.55batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_22/score.txt\n",
      "epoch:22, test:  val_ACC=0.8418, HTER=0.1583, AUC=0.9144, val_err=0.1582, ACC=0.8418, TPR=0.7050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████████████████████| 3342/3342 [08:33<00:00,  6.51batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.8980e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.6500e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(1.5576e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|████████████████████████████| 349/349 [00:53<00:00,  6.52batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_23/score.txt\n",
      "epoch:23, test:  val_ACC=0.8231, HTER=0.1769, AUC=0.8948, val_err=0.1769, ACC=0.8231, TPR=0.6530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████████████████████| 3342/3342 [08:36<00:00,  6.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.4480e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.0678e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(1.9466e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|████████████████████████████| 349/349 [00:52<00:00,  6.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_24/score.txt\n",
      "epoch:24, test:  val_ACC=0.8577, HTER=0.1423, AUC=0.9318, val_err=0.1423, ACC=0.8577, TPR=0.7202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████████████████████| 3342/3342 [08:36<00:00,  6.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.7828e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.1787e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(2.3438e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|████████████████████████████| 349/349 [00:54<00:00,  6.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_25/score.txt\n",
      "epoch:25, test:  val_ACC=0.8248, HTER=0.1752, AUC=0.9033, val_err=0.1753, ACC=0.8248, TPR=0.6549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████████████████████| 3342/3342 [08:35<00:00,  6.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(2.8785e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(4.0946e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(9.6668e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(1.2971e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|████████████████████████████| 349/349 [00:51<00:00,  6.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_26/score.txt\n",
      "epoch:26, test:  val_ACC=0.8646, HTER=0.1355, AUC=0.9221, val_err=0.1354, ACC=0.8646, TPR=0.7090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████████████████████| 3342/3342 [08:34<00:00,  6.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(9.2668e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(8.2748e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(9.9736e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(1.7520e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|████████████████████████████| 349/349 [00:55<00:00,  6.29batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_27/score.txt\n",
      "epoch:27, test:  val_ACC=0.9424, HTER=0.2436, AUC=0.7996, val_err=0.2490, ACC=0.9424, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████████████████████| 3342/3342 [08:39<00:00,  6.43batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(7.8686e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.8053e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(9.7925e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(1.3624e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|████████████████████████████| 349/349 [00:51<00:00,  6.75batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_28/score.txt\n",
      "epoch:28, test:  val_ACC=0.8289, HTER=0.1711, AUC=0.8974, val_err=0.1711, ACC=0.8289, TPR=0.6205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████████████████████| 3342/3342 [08:38<00:00,  6.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.0797e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(2.2140e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(9.4309e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(1.2282e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|████████████████████████████| 349/349 [00:53<00:00,  6.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_29/score.txt\n",
      "epoch:29, test:  val_ACC=0.9639, HTER=0.2325, AUC=0.7860, val_err=0.3157, ACC=0.9639, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████████████████████| 3342/3342 [08:37<00:00,  6.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(8.6042e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(7.1941e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(9.2485e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(1.5090e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|████████████████████████████| 349/349 [00:52<00:00,  6.69batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_30/score.txt\n",
      "epoch:30, test:  val_ACC=0.8273, HTER=0.1728, AUC=0.9091, val_err=0.1728, ACC=0.8273, TPR=0.7127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████████████████████| 3342/3342 [08:35<00:00,  6.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(7.3094e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(5.5029e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(9.1726e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(1.4306e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|████████████████████████████| 349/349 [00:51<00:00,  6.74batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_31/score.txt\n",
      "epoch:31, test:  val_ACC=0.6894, HTER=0.3109, AUC=0.7449, val_err=0.3107, ACC=0.6894, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████████████████████| 3342/3342 [08:32<00:00,  6.52batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(6.0257e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(5.3751e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(8.4127e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(1.3315e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|████████████████████████████| 349/349 [00:53<00:00,  6.52batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_32/score.txt\n",
      "epoch:32, test:  val_ACC=0.8072, HTER=0.1928, AUC=0.8894, val_err=0.1928, ACC=0.8072, TPR=0.6070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████████████████████| 3342/3342 [08:35<00:00,  6.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(4.8226e-08, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.0674e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(8.2228e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(8.3131e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|████████████████████████████| 349/349 [00:52<00:00,  6.61batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_33/score.txt\n",
      "epoch:33, test:  val_ACC=0.9537, HTER=0.2379, AUC=0.7998, val_err=0.2844, ACC=0.9537, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████████████████████| 3342/3342 [08:34<00:00,  6.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(3.3458e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(4.7627e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(7.4652e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(1.4621e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|████████████████████████████| 349/349 [00:51<00:00,  6.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_34/score.txt\n",
      "epoch:34, test:  val_ACC=0.8403, HTER=0.1598, AUC=0.9277, val_err=0.1598, ACC=0.8403, TPR=0.7538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████████████████████| 3342/3342 [08:38<00:00,  6.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.3803e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(9.1307e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(6.4354e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(1.3878e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|████████████████████████████| 349/349 [00:52<00:00,  6.71batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_35/score.txt\n",
      "epoch:35, test:  val_ACC=0.8574, HTER=0.1427, AUC=0.9425, val_err=0.1427, ACC=0.8574, TPR=0.7465\n",
      "improve acc .. .. ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████████████████████| 3342/3342 [08:33<00:00,  6.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(3.5365e-08, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(5.1790e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(6.5505e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(1.0697e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|████████████████████████████| 349/349 [00:52<00:00,  6.67batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_36/score.txt\n",
      "epoch:36, test:  val_ACC=0.8196, HTER=0.1804, AUC=0.9035, val_err=0.1805, ACC=0.8196, TPR=0.6660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████████████████████| 3342/3342 [08:36<00:00,  6.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(6.0343e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.8351e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(7.2952e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(9.3667e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|████████████████████████████| 349/349 [00:52<00:00,  6.59batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_37/score.txt\n",
      "epoch:37, test:  val_ACC=0.8622, HTER=0.1379, AUC=0.9319, val_err=0.1379, ACC=0.8622, TPR=0.7387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████████████████████| 3342/3342 [08:40<00:00,  6.42batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(9.4573e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(8.4661e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(6.5158e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(1.4234e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|████████████████████████████| 349/349 [00:50<00:00,  6.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_38/score.txt\n",
      "epoch:38, test:  val_ACC=0.8134, HTER=0.1867, AUC=0.9112, val_err=0.1867, ACC=0.8134, TPR=0.6651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████████████████████| 3342/3342 [08:33<00:00,  6.51batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(7.5192e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(6.1579e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(6.6304e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(1.2309e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|████████████████████████████| 349/349 [00:53<00:00,  6.52batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_39/score.txt\n",
      "epoch:39, test:  val_ACC=0.7962, HTER=0.2043, AUC=0.8383, val_err=0.2046, ACC=0.7962, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████████████████████| 3342/3342 [08:34<00:00,  6.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(2.2754e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.1787e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(5.6051e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(8.3756e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|████████████████████████████| 349/349 [00:52<00:00,  6.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_40/score.txt\n",
      "epoch:40, test:  val_ACC=0.8898, HTER=0.1102, AUC=0.9518, val_err=0.1103, ACC=0.8898, TPR=0.8211\n",
      "improve acc .. .. ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████████████████████| 3342/3342 [08:34<00:00,  6.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.0213e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(4.0685e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(6.4755e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(9.7405e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|████████████████████████████| 349/349 [00:54<00:00,  6.42batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_41/score.txt\n",
      "epoch:41, test:  val_ACC=0.8251, HTER=0.1750, AUC=0.9111, val_err=0.1750, ACC=0.8251, TPR=0.6821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████████████████████| 3342/3342 [08:39<00:00,  6.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(3.3266e-08, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.5012e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(5.9815e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(6.2649e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|████████████████████████████| 349/349 [00:52<00:00,  6.71batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_42/score.txt\n",
      "epoch:42, test:  val_ACC=0.8537, HTER=0.1464, AUC=0.9364, val_err=0.1464, ACC=0.8537, TPR=0.7604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████████████████████| 3342/3342 [08:30<00:00,  6.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.2463e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(9.2281e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(5.0822e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(1.3711e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|████████████████████████████| 349/349 [00:55<00:00,  6.28batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_43/score.txt\n",
      "epoch:43, test:  val_ACC=0.8304, HTER=0.1696, AUC=0.9009, val_err=0.1696, ACC=0.8304, TPR=0.6814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████████████████████| 3342/3342 [08:30<00:00,  6.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(2.4695e-08, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.9978e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(5.3735e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(8.5742e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|████████████████████████████| 349/349 [00:54<00:00,  6.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_44/score.txt\n",
      "epoch:44, test:  val_ACC=0.8384, HTER=0.1616, AUC=0.9144, val_err=0.1616, ACC=0.8384, TPR=0.6844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████████████████████| 3342/3342 [08:35<00:00,  6.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(5.9542e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.2049e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(4.9119e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(7.5353e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|████████████████████████████| 349/349 [00:52<00:00,  6.67batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_45/score.txt\n",
      "epoch:45, test:  val_ACC=0.9567, HTER=0.2137, AUC=0.8171, val_err=0.2481, ACC=0.9567, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████████████████████| 3342/3342 [08:33<00:00,  6.51batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(7.5306e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.1920e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(4.8114e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(8.1181e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|████████████████████████████| 349/349 [00:51<00:00,  6.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_46/score.txt\n",
      "epoch:46, test:  val_ACC=0.8577, HTER=0.1423, AUC=0.9196, val_err=0.1423, ACC=0.8577, TPR=0.7300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████████████████████| 3342/3342 [08:35<00:00,  6.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(8.5883e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(7.2606e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(4.9401e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(1.1607e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|████████████████████████████| 349/349 [00:54<00:00,  6.37batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_47/score.txt\n",
      "epoch:47, test:  val_ACC=0.8470, HTER=0.1531, AUC=0.9184, val_err=0.1530, ACC=0.8470, TPR=0.6376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████████████████████| 3342/3342 [08:35<00:00,  6.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.3306e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(5.1257e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(4.3518e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(8.4657e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|████████████████████████████| 349/349 [00:52<00:00,  6.63batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_48/score.txt\n",
      "epoch:48, test:  val_ACC=0.8535, HTER=0.1466, AUC=0.9181, val_err=0.1466, ACC=0.8535, TPR=0.8029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████████████████████| 3342/3342 [08:37<00:00,  6.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.0445e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(4.0772e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(5.0752e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(9.3815e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|████████████████████████████| 349/349 [00:52<00:00,  6.61batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_49/score.txt\n",
      "epoch:49, test:  val_ACC=0.8093, HTER=0.1908, AUC=0.8845, val_err=0.1907, ACC=0.8093, TPR=0.6530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████████████████████| 3342/3342 [08:32<00:00,  6.52batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.2371e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.7563e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(4.5850e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(7.7137e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|████████████████████████████| 349/349 [00:52<00:00,  6.61batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_50/score.txt\n",
      "epoch:50, test:  val_ACC=0.8471, HTER=0.1529, AUC=0.9226, val_err=0.1530, ACC=0.8471, TPR=0.7066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████████████████████| 3342/3342 [08:35<00:00,  6.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(2.2989e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.3264e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(4.2459e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(4.5819e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|████████████████████████████| 349/349 [00:53<00:00,  6.58batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_51/score.txt\n",
      "epoch:51, test:  val_ACC=0.8292, HTER=0.1709, AUC=0.9110, val_err=0.1709, ACC=0.8292, TPR=0.6708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████████████████████| 3342/3342 [08:34<00:00,  6.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(3.1593e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.6752e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(4.4937e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(7.7498e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|████████████████████████████| 349/349 [00:51<00:00,  6.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_52/score.txt\n",
      "epoch:52, test:  val_ACC=0.8160, HTER=0.1840, AUC=0.8916, val_err=0.1840, ACC=0.8160, TPR=0.6899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████████████████████| 3342/3342 [08:41<00:00,  6.41batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(4.6415e-08, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(4.9232e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(4.1024e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(8.0456e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|████████████████████████████| 349/349 [00:52<00:00,  6.67batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_53/score.txt\n",
      "epoch:53, test:  val_ACC=0.8337, HTER=0.1663, AUC=0.9148, val_err=0.1663, ACC=0.8337, TPR=0.6613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████████████████████| 3342/3342 [08:36<00:00,  6.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.9626e-09, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.4993e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(3.8771e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(6.6767e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|████████████████████████████| 349/349 [00:54<00:00,  6.43batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_54/score.txt\n",
      "epoch:54, test:  val_ACC=0.8763, HTER=0.1238, AUC=0.9412, val_err=0.1238, ACC=0.8763, TPR=0.8183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████████████████████| 3342/3342 [08:36<00:00,  6.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(6.7064e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.6038e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(4.0287e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(7.5824e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|████████████████████████████| 349/349 [00:52<00:00,  6.68batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_55/score.txt\n",
      "epoch:55, test:  val_ACC=0.8297, HTER=0.1703, AUC=0.9105, val_err=0.1703, ACC=0.8297, TPR=0.6662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████████████████████| 3342/3342 [08:37<00:00,  6.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(6.0989e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(4.9380e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(4.1150e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(8.1264e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|████████████████████████████| 349/349 [00:51<00:00,  6.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_56/score.txt\n",
      "epoch:56, test:  val_ACC=0.7653, HTER=0.2347, AUC=0.8450, val_err=0.2348, ACC=0.7653, TPR=0.5179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████████████████████| 3342/3342 [08:37<00:00,  6.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.0964e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(5.2948e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(3.6796e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(9.0118e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|████████████████████████████| 349/349 [00:51<00:00,  6.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_57/score.txt\n",
      "epoch:57, test:  val_ACC=0.8284, HTER=0.1716, AUC=0.9015, val_err=0.1716, ACC=0.8284, TPR=0.6530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████████████████████| 3342/3342 [08:35<00:00,  6.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(6.7424e-08, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.1057e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(3.9101e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(6.4014e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|████████████████████████████| 349/349 [00:51<00:00,  6.81batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_58/score.txt\n",
      "epoch:58, test:  val_ACC=0.8315, HTER=0.1685, AUC=0.9123, val_err=0.1685, ACC=0.8315, TPR=0.6751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████████████████████| 3342/3342 [08:35<00:00,  6.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(4.2420e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.8568e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(4.1515e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(7.6611e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|████████████████████████████| 349/349 [00:55<00:00,  6.33batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_59/score.txt\n",
      "epoch:59, test:  val_ACC=0.8232, HTER=0.1768, AUC=0.9028, val_err=0.1768, ACC=0.8232, TPR=0.6632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|██████████████████████████| 3342/3342 [08:37<00:00,  6.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(9.4563e-08, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.9664e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(3.2676e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(4.8502e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|████████████████████████████| 349/349 [00:51<00:00,  6.82batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_60/score.txt\n",
      "epoch:60, test:  val_ACC=0.8109, HTER=0.1891, AUC=0.8860, val_err=0.1892, ACC=0.8109, TPR=0.6170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|██████████████████████████| 3342/3342 [08:36<00:00,  6.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(5.0456e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(2.4993e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(3.9655e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(6.0154e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|████████████████████████████| 349/349 [00:52<00:00,  6.60batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_61/score.txt\n",
      "epoch:61, test:  val_ACC=0.9716, HTER=0.1970, AUC=0.8264, val_err=0.2765, ACC=0.9716, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|██████████████████████████| 3342/3342 [08:35<00:00,  6.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.0780e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.5753e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(3.5790e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(7.5173e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|████████████████████████████| 349/349 [00:53<00:00,  6.58batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_62/score.txt\n",
      "epoch:62, test:  val_ACC=0.8101, HTER=0.1898, AUC=0.8991, val_err=0.1899, ACC=0.8101, TPR=0.5702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|██████████████████████████| 3342/3342 [08:38<00:00,  6.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(4.4050e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.7335e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(3.7379e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(3.9206e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|████████████████████████████| 349/349 [00:52<00:00,  6.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_63/score.txt\n",
      "epoch:63, test:  val_ACC=0.8132, HTER=0.1868, AUC=0.8795, val_err=0.1868, ACC=0.8132, TPR=0.5801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|██████████████████████████| 3342/3342 [08:37<00:00,  6.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.0174e-08, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.1767e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(3.8864e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(1.3301e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|████████████████████████████| 349/349 [00:53<00:00,  6.52batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_64/score.txt\n",
      "epoch:64, test:  val_ACC=0.8330, HTER=0.1670, AUC=0.9072, val_err=0.1670, ACC=0.8330, TPR=0.6515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|██████████████████████████| 3342/3342 [08:35<00:00,  6.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(5.7770e-09, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(2.2783e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(4.0234e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(5.8466e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|████████████████████████████| 349/349 [00:53<00:00,  6.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_65/score.txt\n",
      "epoch:65, test:  val_ACC=0.8827, HTER=0.1173, AUC=0.9434, val_err=0.1173, ACC=0.8827, TPR=0.7820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66: 100%|██████████████████████████| 3342/3342 [08:35<00:00,  6.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(7.0761e-10, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(4.2111e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(2.3831e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(5.7521e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66: 100%|████████████████████████████| 349/349 [00:53<00:00,  6.58batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_66/score.txt\n",
      "epoch:66, test:  val_ACC=0.8202, HTER=0.1798, AUC=0.9011, val_err=0.1798, ACC=0.8202, TPR=0.5873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 100%|██████████████████████████| 3342/3342 [08:38<00:00,  6.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(2.3023e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.3114e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(3.6676e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(6.0748e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 100%|████████████████████████████| 349/349 [00:53<00:00,  6.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_67/score.txt\n",
      "epoch:67, test:  val_ACC=0.8479, HTER=0.1522, AUC=0.9197, val_err=0.1522, ACC=0.8479, TPR=0.6484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 100%|██████████████████████████| 3342/3342 [08:34<00:00,  6.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(4.3143e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(2.2073e-08, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(3.4905e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(3.9395e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 100%|████████████████████████████| 349/349 [00:52<00:00,  6.62batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_68/score.txt\n",
      "epoch:68, test:  val_ACC=0.7414, HTER=0.2611, AUC=0.7920, val_err=0.2628, ACC=0.7414, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 100%|██████████████████████████| 3342/3342 [08:36<00:00,  6.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(6.0734e-08, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(5.9346e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(2.7601e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(7.5138e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 100%|████████████████████████████| 349/349 [00:53<00:00,  6.58batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_69/score.txt\n",
      "epoch:69, test:  val_ACC=0.7900, HTER=0.2103, AUC=0.8353, val_err=0.2104, ACC=0.7900, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70: 100%|██████████████████████████| 3342/3342 [08:36<00:00,  6.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(3.4505e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(2.2618e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(3.1232e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(5.2776e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70: 100%|████████████████████████████| 349/349 [00:50<00:00,  6.87batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_70/score.txt\n",
      "epoch:70, test:  val_ACC=0.7137, HTER=0.2863, AUC=0.7836, val_err=0.2863, ACC=0.7137, TPR=0.3700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71: 100%|██████████████████████████| 3342/3342 [08:34<00:00,  6.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(8.0884e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.0391e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(2.5795e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(4.2196e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71: 100%|████████████████████████████| 349/349 [00:53<00:00,  6.56batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_71/score.txt\n",
      "epoch:71, test:  val_ACC=0.7936, HTER=0.2064, AUC=0.8498, val_err=0.2064, ACC=0.7936, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72: 100%|██████████████████████████| 3342/3342 [08:35<00:00,  6.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(3.6686e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.2237e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(3.4620e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(6.0776e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72: 100%|████████████████████████████| 349/349 [00:53<00:00,  6.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_72/score.txt\n",
      "epoch:72, test:  val_ACC=0.8170, HTER=0.1830, AUC=0.8947, val_err=0.1830, ACC=0.8170, TPR=0.5938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73: 100%|██████████████████████████| 3342/3342 [08:37<00:00,  6.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(2.5309e-09, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.1612e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(3.0034e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(5.5326e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73: 100%|████████████████████████████| 349/349 [00:53<00:00,  6.56batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_73/score.txt\n",
      "epoch:73, test:  val_ACC=0.8807, HTER=0.1193, AUC=0.9370, val_err=0.1193, ACC=0.8807, TPR=0.8115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74: 100%|██████████████████████████| 3342/3342 [08:38<00:00,  6.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(4.8700e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(2.8248e-08, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(3.4887e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(3.9983e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74: 100%|████████████████████████████| 349/349 [00:51<00:00,  6.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_74/score.txt\n",
      "epoch:74, test:  val_ACC=0.8644, HTER=0.1356, AUC=0.9256, val_err=0.1356, ACC=0.8644, TPR=0.7230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75: 100%|██████████████████████████| 3342/3342 [08:37<00:00,  6.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.4894e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(2.7783e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(2.4734e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(6.1855e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75: 100%|████████████████████████████| 349/349 [00:52<00:00,  6.59batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_75/score.txt\n",
      "epoch:75, test:  val_ACC=0.8418, HTER=0.1583, AUC=0.9062, val_err=0.1583, ACC=0.8418, TPR=0.6639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76: 100%|██████████████████████████| 3342/3342 [08:40<00:00,  6.42batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.5772e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.0586e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(2.9543e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(5.3784e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76: 100%|████████████████████████████| 349/349 [00:51<00:00,  6.71batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_76/score.txt\n",
      "epoch:76, test:  val_ACC=0.8281, HTER=0.1720, AUC=0.8916, val_err=0.1720, ACC=0.8281, TPR=0.6296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77: 100%|██████████████████████████| 3342/3342 [08:32<00:00,  6.52batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.2871e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(6.4352e-08, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(2.6782e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(2.7425e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77: 100%|████████████████████████████| 349/349 [00:52<00:00,  6.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_77/score.txt\n",
      "epoch:77, test:  val_ACC=0.8273, HTER=0.1728, AUC=0.8920, val_err=0.1728, ACC=0.8273, TPR=0.6563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78: 100%|██████████████████████████| 3342/3342 [08:36<00:00,  6.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(6.8931e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(2.6540e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(2.9825e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(5.7950e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78: 100%|████████████████████████████| 349/349 [00:51<00:00,  6.75batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_78/score.txt\n",
      "epoch:78, test:  val_ACC=0.9583, HTER=0.1781, AUC=0.8550, val_err=0.1835, ACC=0.9583, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79: 100%|██████████████████████████| 3342/3342 [08:38<00:00,  6.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(2.8032e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(2.9522e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(2.4492e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(4.8390e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79: 100%|████████████████████████████| 349/349 [00:53<00:00,  6.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_79/score.txt\n",
      "epoch:79, test:  val_ACC=0.8059, HTER=0.1941, AUC=0.8799, val_err=0.1941, ACC=0.8059, TPR=0.6216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80: 100%|██████████████████████████| 3342/3342 [08:36<00:00,  6.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(3.8203e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.2207e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(2.6336e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(3.9921e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80: 100%|████████████████████████████| 349/349 [00:51<00:00,  6.78batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_80/score.txt\n",
      "epoch:80, test:  val_ACC=0.8544, HTER=0.1459, AUC=0.9023, val_err=0.1459, ACC=0.8544, TPR=0.8040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81: 100%|██████████████████████████| 3342/3342 [08:39<00:00,  6.43batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(9.8636e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.8053e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(2.7040e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(5.8469e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81: 100%|████████████████████████████| 349/349 [00:52<00:00,  6.69batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_81/score.txt\n",
      "epoch:81, test:  val_ACC=0.7958, HTER=0.2043, AUC=0.8642, val_err=0.2043, ACC=0.7958, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82: 100%|██████████████████████████| 3342/3342 [08:41<00:00,  6.41batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(5.2113e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(5.9469e-08, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(2.3811e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(2.9499e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82: 100%|████████████████████████████| 349/349 [00:54<00:00,  6.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_82/score.txt\n",
      "epoch:82, test:  val_ACC=0.9548, HTER=0.2212, AUC=0.8153, val_err=0.2553, ACC=0.9548, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83: 100%|██████████████████████████| 3342/3342 [08:35<00:00,  6.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(6.9943e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(2.2357e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(2.8924e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(5.3805e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83: 100%|████████████████████████████| 349/349 [00:51<00:00,  6.78batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_83/score.txt\n",
      "epoch:83, test:  val_ACC=0.8536, HTER=0.1464, AUC=0.9235, val_err=0.1464, ACC=0.8536, TPR=0.6792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84: 100%|██████████████████████████| 3342/3342 [08:35<00:00,  6.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.7727e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(8.4562e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(2.5165e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(3.2107e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84: 100%|████████████████████████████| 349/349 [00:52<00:00,  6.63batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_84/score.txt\n",
      "epoch:84, test:  val_ACC=0.8144, HTER=0.1860, AUC=0.8679, val_err=0.1858, ACC=0.8144, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85: 100%|██████████████████████████| 3342/3342 [08:38<00:00,  6.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(7.0342e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(4.1724e-08, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(2.6002e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(3.3370e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85: 100%|████████████████████████████| 349/349 [00:53<00:00,  6.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_85/score.txt\n",
      "epoch:85, test:  val_ACC=0.8167, HTER=0.1833, AUC=0.8815, val_err=0.1834, ACC=0.8167, TPR=0.5571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86:  82%|█████████████████████▍    | 2749/3342 [07:08<01:32,  6.41batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m best_auc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m***************************\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#print(\"train : \")\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m#train_auc = test(train_loader,epoch)\u001b[39;00m\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m    265\u001b[0m loss_all \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\u001b[38;5;241m*\u001b[39m adv_loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.8\u001b[39m\u001b[38;5;241m*\u001b[39mloss_cls \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.1\u001b[39m\u001b[38;5;241m*\u001b[39mnode_cls_loss\n\u001b[1;32m    266\u001b[0m loss_all\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Derive gradients.\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Update parameters based on gradients.\u001b[39;00m\n\u001b[1;32m    268\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Clear gradients.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m loss_all \u001b[38;5;241m+\u001b[39m total_loss\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/site-packages/torch/optim/optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/site-packages/torch/optim/adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    155\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 157\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/site-packages/torch/optim/adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 213\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/site-packages/torch/optim/adam.py:307\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(\"V_10_without_pipline_domain_generalization_tuning.pth\",map_location='cuda'))\n",
    "# best_auc = 0.9862\n",
    "best_auc = 0\n",
    "for epoch in range(0, 1000):\n",
    "    train(epoch)\n",
    "    print(\"***************************\")\n",
    "    #print(\"train : \")\n",
    "    #train_auc = test(train_loader,epoch)\n",
    "    print(\"test : \")\n",
    "    test_auc = test(test_loader,epoch)\n",
    "    if test_auc > best_auc:\n",
    "        print(\"improve acc .. .. ..\")\n",
    "        torch.save(model.state_dict(), 'corrcted_V_10_without_pipline_domain_generalization_tuning.pth')\n",
    "        best_auc = test_auc\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dff8e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"V_10_without_pipline_domain_generalization_tuning.pth\",map_location='cuda'))\n",
    "best_auc = 0.9862\n",
    "# best_auc = 0\n",
    "for epoch in range(0, 1000):\n",
    "    train(epoch)\n",
    "    print(\"***************************\")\n",
    "    #print(\"train : \")\n",
    "    #train_auc = test(train_loader,epoch)\n",
    "    print(\"test : \")\n",
    "    test_auc = test(test_loader,epoch)\n",
    "    if test_auc > best_auc:\n",
    "        print(\"improve acc .. .. ..\")\n",
    "        torch.save(model.state_dict(), 'arg_contrast_bright_V_10_without_pipline_domain_generalization_tuning.pth')\n",
    "        best_auc = test_auc\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38525b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"V_10_without_pipline_domain_generalization_tuning.pth\",map_location='cuda'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f1a82ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): ChebConv(640, 128, K=2, normalization=sym)\n",
      "  (conv2): ChebConv(128, 128, K=2, normalization=sym)\n",
      "  (conv3): ChebConv(128, 128, K=2, normalization=sym)\n",
      "  (conv4): ChebConv(128, 128, K=2, normalization=sym)\n",
      "  (conv5): ChebConv(256, 128, K=2, normalization=sym)\n",
      "  (conv6): ChebConv(128, 128, K=2, normalization=sym)\n",
      "  (conv7): ChebConv(128, 128, K=2, normalization=sym)\n",
      "  (conv8): ChebConv(128, 128, K=2, normalization=sym)\n",
      "  (lin): SimpleTransformer(\n",
      "    (linear): Linear(in_features=4, out_features=8, bias=True)\n",
      "    (encoder_layer): TransformerEncoderLayer(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "      )\n",
      "      (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "      (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Linear(in_features=1024, out_features=1, bias=True)\n",
      "  )\n",
      "  (drop_1): RandomNodeDropout()\n",
      "  (drop_2): RandomNodeDropout()\n",
      "  (drop_3): RandomNodeDropout()\n",
      "  (drop_4): RandomNodeDropout()\n",
      "  (drop_5): RandomNodeDropout()\n",
      "  (drop_6): RandomNodeDropout()\n",
      "  (b1): BatchNorm(128)\n",
      "  (b2): BatchNorm(128)\n",
      "  (b3): BatchNorm(128)\n",
      "  (b4): BatchNorm(128)\n",
      "  (b5): BatchNorm(128)\n",
      "  (b6): BatchNorm(128)\n",
      "  (b7): BatchNorm(128)\n",
      "  (dis): Discriminator(\n",
      "    (conv1): GraphSAGE(128, 128, num_layers=2)\n",
      "    (conv2): GraphSAGE(128, 128, num_layers=2)\n",
      "    (conv3): GraphSAGE(128, 128, num_layers=2)\n",
      "    (conv4): GraphSAGE(128, 128, num_layers=2)\n",
      "    (drop_1): RandomNodeDropout()\n",
      "    (drop_2): RandomNodeDropout()\n",
      "    (grl_layer): GRL()\n",
      "    (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (conv1_node_class): GraphSAGE(128, 128, num_layers=2)\n",
      "  (conv2_node_class): GraphSAGE(128, 128, num_layers=2)\n",
      "  (lin_node_class): SimpleTransformer_2(\n",
      "    (linear): Linear(in_features=1, out_features=64, bias=True)\n",
      "    (encoder_layer): TransformerEncoderLayer(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "      (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (6): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (7): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (8): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (9): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Linear(in_features=8192, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Discriminator_Global(nn.Module):\n",
    "    def __init__(self, max_iter=4000):\n",
    "        super(Discriminator_Global, self).__init__()\n",
    "        self.fc1 = self.lin = SimpleTransformer(8,5,8,3)\n",
    "        self.ad_net = nn.Sequential(\n",
    "            self.fc1\n",
    "        )\n",
    "        self.grl_layer = GRL(max_iter)\n",
    "\n",
    "    def forward(self, feature):\n",
    "        adversarial_out = self.ad_net(self.grl_layer(feature))\n",
    "        return adversarial_out\n",
    "\n",
    "\n",
    "\n",
    "class RandomNodeDropout(nn.Module):\n",
    "    def __init__(self, drop_prob=0.3):\n",
    "        super(RandomNodeDropout, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x, enabled=True):\n",
    "        if not self.training or not enabled:\n",
    "            return x\n",
    "        \n",
    "        num_rows = x.size(0)\n",
    "        mask = torch.rand(num_rows, device=x.device) > self.drop_prob\n",
    "        mask = mask.float().unsqueeze(1).expand_as(x)\n",
    "        x = x * mask\n",
    "        \n",
    "        return x\n",
    "\n",
    "soft = torch.nn.Softmax(dim=1)\n",
    "\n",
    "num_domain = 3\n",
    "class GRL(nn.Module):\n",
    "\n",
    "    def __init__(self, max_iter):\n",
    "        super(GRL, self).__init__()\n",
    "        self.iter_num = 0\n",
    "        self.alpha = 10\n",
    "        self.low = 0.0\n",
    "        self.high = 1.0\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.iter_num += 1\n",
    "        return input * 1.0\n",
    "\n",
    "    def backward(self, gradOutput):\n",
    "        coeff = np.float(2.0 * (self.high - self.low) / (1.0 + np.exp(-self.alpha * self.iter_num / self.max_iter))\n",
    "                         - (self.high - self.low) + self.low)\n",
    "        return -coeff*10* gradOutput\n",
    "\n",
    "num_node  =train_dataset.num_node_features\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self,hidden_channels ,max_iter):\n",
    "        super(Discriminator, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GraphSAGE(hidden_channels, hidden_channels,2,dropout=0.5)\n",
    "        self.conv2 = GraphSAGE(hidden_channels, hidden_channels,2,dropout=0.5)\n",
    "        self.conv3 = GraphSAGE(hidden_channels, hidden_channels,2,dropout=0.5)\n",
    "        self.conv4 = GraphSAGE(hidden_channels, hidden_channels,2,dropout=0.5)\n",
    "        self.drop_1 = RandomNodeDropout(drop_prob=0.3)\n",
    "        self.drop_2 = RandomNodeDropout(drop_prob=0.3)\n",
    "        self.grl_layer = GRL(max_iter)\n",
    "        self.fc2 = nn.Linear(hidden_channels, num_domain)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch,drop_en):\n",
    "        #print(\"graph fea :\",graph_level_feature.shape ,edge_index.shape )\n",
    "        \n",
    "        x = self.grl_layer(x)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.drop_1(x,drop_en)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.drop_2(x,drop_en)\n",
    "        \n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "         \n",
    "        return x \n",
    "\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels,max_iter=4000):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = ChebConv(num_node, hidden_channels,2)\n",
    "        self.conv2 = ChebConv(hidden_channels, hidden_channels,2)\n",
    "        self.conv3 = ChebConv(hidden_channels, hidden_channels,2)\n",
    "        self.conv4 = ChebConv(hidden_channels, hidden_channels,2)\n",
    "        self.conv5 = ChebConv(hidden_channels*2, hidden_channels,2)\n",
    "        self.conv6 = ChebConv(hidden_channels, hidden_channels,2)\n",
    "        self.conv7 = ChebConv(hidden_channels, hidden_channels,2)\n",
    "        self.conv8 = ChebConv(hidden_channels, hidden_channels,2)\n",
    "        self.lin = SimpleTransformer(8,5,8,1)\n",
    "        \n",
    "        self.drop_1 = RandomNodeDropout(drop_prob=0.1)\n",
    "        self.drop_2 = RandomNodeDropout(drop_prob=0.1)\n",
    "        self.drop_3 = RandomNodeDropout(drop_prob=0.1)\n",
    "        self.drop_4 = RandomNodeDropout(drop_prob=0.1)\n",
    "        self.drop_5 = RandomNodeDropout(drop_prob=0.1)\n",
    "        self.drop_6 = RandomNodeDropout(drop_prob=0.1)\n",
    "        \n",
    "        \n",
    "        self.b1 = BatchNorm(hidden_channels)\n",
    "        self.b2 = BatchNorm(hidden_channels)\n",
    "        self.b3 = BatchNorm(hidden_channels)\n",
    "        self.b4 = BatchNorm(hidden_channels)\n",
    "        self.b5 = BatchNorm(hidden_channels)\n",
    "        self.b6 = BatchNorm(hidden_channels)\n",
    "        self.b7 = BatchNorm(hidden_channels)\n",
    "        \n",
    "        self.dis = Discriminator(hidden_channels,max_iter)\n",
    "        \n",
    "        self.conv1_node_class = GraphSAGE(hidden_channels, hidden_channels,2,dropout=0.5)\n",
    "        \n",
    "        self.conv2_node_class = GraphSAGE(hidden_channels, hidden_channels,2,dropout=0.5)\n",
    "        \n",
    "        self.lin_node_class = SimpleTransformer_2(64,10,8)\n",
    "        \n",
    "\n",
    "        \n",
    "        #self.tcn = Simple1DCNN()\n",
    "        \n",
    "    def forward(self, x, edge_index, batch,drop_en,index_arr):\n",
    "        #print(\"graph fea :\",graph_level_feature.shape ,edge_index.shape )\n",
    "        \n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x  = self.b1(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        #x = self.drop_1(x,drop_en)\n",
    "        \n",
    "        \n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x  = self.b2(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        #x = self.drop_2(x,drop_en)\n",
    "                \n",
    "        dicriminator = x\n",
    "        \n",
    "        x_1 = global_mean_pool(x, batch)\n",
    "        \n",
    "        x = self.conv3(x, edge_index)\n",
    "        x  = self.b3(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = self.drop_3(x,drop_en)\n",
    "        \n",
    "        x_3 = global_mean_pool(x, batch)\n",
    "        \n",
    "        \n",
    "        x = self.conv4(x, edge_index)\n",
    "        x  = self.b4(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = self.drop_4(x,drop_en)\n",
    "        \n",
    "        \n",
    "        x = torch.cat((x,dicriminator),dim=1) #skip connection\n",
    "        \n",
    "        x = self.conv5(x, edge_index)\n",
    "        x  = self.b5(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = self.drop_5(x,drop_en)\n",
    "        \n",
    "        x_5 = global_mean_pool(x, batch)\n",
    "        \n",
    "        x = self.conv6(x, edge_index)\n",
    "        x  = self.b6(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = self.drop_6(x,drop_en)\n",
    "        \n",
    "        x = self.conv7(x, edge_index)\n",
    "        x  = self.b7(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        \n",
    "        x = self.conv8(x, edge_index)\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "        \n",
    "        x = torch.stack([x,x_1,x_5,x_3],dim=2)\n",
    "        \n",
    "        combined_features = x\n",
    "        \n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        \n",
    "        #x = torch.unsqueeze(x,2)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        x = self.lin(x)\n",
    "        \n",
    "        x= x.sigmoid()\n",
    "        \n",
    "        \n",
    "        node_class_hidden = self.conv1_node_class(dicriminator,edge_index)\n",
    "        node_class_hidden = node_class_hidden.relu()\n",
    "        \n",
    "        node_class_hidden = self.conv2_node_class(node_class_hidden,edge_index)\n",
    "        node_class_hidden = node_class_hidden.relu()\n",
    "        \n",
    "        #print(index_arr.shape , node_class_hidden.shape)\n",
    "        \n",
    "        node_class_hidden = node_class_hidden[index_arr]\n",
    "        \n",
    "        #print(node_class_hidden.shape)\n",
    "        node_class_hidden = torch.unsqueeze(node_class_hidden, dim=2)\n",
    "        \n",
    "        node_pre = self.lin_node_class(node_class_hidden)\n",
    "        \n",
    "            \n",
    "        #print(\"hiiii :\" , dicriminator.shape)\n",
    "        dis_invariant = self.dis(dicriminator,edge_index,batch,drop_en)\n",
    "        \n",
    "        return x ,dis_invariant ,node_pre ,combined_features\n",
    "\n",
    "model = GCN(hidden_channels=128).to(device)\n",
    "print(model)\n",
    "g_dis = Discriminator_Global().to(device)\n",
    "\n",
    "def check_folder(log_dir):\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    return log_dir\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "#optimizer_ = torch.optim.Adam(g_dis.parameters(), lr=0.00001)\n",
    "\n",
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion= nn.BCELoss()\n",
    "criterion_node_class=  torch.nn.CrossEntropyLoss()\n",
    "criterion_2 = torch.nn.CrossEntropyLoss()\n",
    "globla_adv_criterion_2 = torch.nn.CrossEntropyLoss() \n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    losses_adv_loss=0\n",
    "    losses_loss_cls=0\n",
    "    total_loss = 0\n",
    "    losses_node_cls_loss = 0\n",
    "    losses_g_adv_loss=0\n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}', unit='batch')\n",
    "    for graph in progress_bar:  # Iterate in batches over the training dataset.\n",
    "        graph = graph.to(device)  # Move data to the device\n",
    "        \n",
    "        drop_en = bool(np.random.binomial(1, 0.5))\n",
    "        \n",
    "        if graph.x.shape[0] < 29952 :\n",
    "            \n",
    "            if graph.x.shape[0] < 64:\n",
    "                            index_arr = torch.randint(0, int(graph.x.shape[0]), (int(graph.x.shape[0]),)).to(device)\n",
    "            else :\n",
    "                \n",
    "                index_arr = torch.randint(0, int(graph.x.shape[0]), (64,)).to(device)\n",
    "        else :\n",
    "                \n",
    "            index_arr = torch.randint(0, 29952, (64,)).to(device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        out,domain_invariant,node_pre,global_avg = model(graph.x, graph.edge_index, graph.batch,drop_en,index_arr)  # Perform a single forward pass.\n",
    "        \n",
    "        \n",
    "        global_adverserial = g_dis(global_avg)\n",
    "        \n",
    "        \n",
    "        g_adv_loss = globla_adv_criterion_2(global_adverserial, graph.data)\n",
    "        \n",
    "        \n",
    "        adv_loss = criterion_2(domain_invariant, graph.data)\n",
    "        \n",
    "        node_cls_loss = criterion_node_class(node_pre.squeeze(),graph.y_node.float()[index_arr])\n",
    "        #print(out.shape , graph.y.long().shape)\n",
    "        loss_cls = criterion(out.squeeze(), graph.y.float())  # Compute the loss.\n",
    "        \n",
    "        loss_all = adv_loss + loss_cls + node_cls_loss+g_adv_loss\n",
    "        loss_all.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "        total_loss = loss_all + total_loss\n",
    "        losses_adv_loss = adv_loss + losses_adv_loss\n",
    "        losses_loss_cls = loss_cls + losses_loss_cls\n",
    "        losses_node_cls_loss = node_cls_loss + losses_node_cls_loss\n",
    "        losses_g_adv_loss = g_adv_loss + losses_g_adv_loss\n",
    "\n",
    "\n",
    "    print(\"/////////////////////////\")\n",
    "    print(\"adverserial loss : \" ,losses_adv_loss/len(train_loader.dataset))  \n",
    "    print(\"classification loss : \" , losses_loss_cls/len(train_loader.dataset))\n",
    "    print(\"classification node loss : \" , losses_node_cls_loss/len(train_loader.dataset))\n",
    "    print(\" g_adv loss: \" , losses_g_adv_loss/len(train_loader.dataset))\n",
    "    print(\"total loss : \" ,total_loss/len(train_loader.dataset) )\n",
    "    print(\"////////////////////////////////////\")\n",
    "def test(loader,epoch):\n",
    "    score_path = os.path.join(\"/home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores\", \"epoch_{}\".format(epoch+1))\n",
    "    check_folder(score_path)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        scores_list = []\n",
    "\n",
    "        correct = 0\n",
    "        s= 0\n",
    "        progress_bar = tqdm(loader, desc=f'Epoch {epoch+1}', unit='batch')\n",
    "        for graph in progress_bar:  # Iterate in batches over the training/test dataset.\n",
    "            if graph.x.shape[0] < 29952 :\n",
    "\n",
    "                if graph.x.shape[0] < 64:\n",
    "\n",
    "                    index_arr = torch.randint(0, int(graph.x.shape[0]), (int(graph.x.shape[0]),)).to(device)\n",
    "                else :\n",
    "\n",
    "                    index_arr = torch.randint(0, int(graph.x.shape[0]), (64,)).to(device)\n",
    "            else :\n",
    "\n",
    "                index_arr = torch.randint(0, 29952, (64,)).to(device)\n",
    "                \n",
    "            graph = graph.to(device)  # Move data to the device\n",
    "            logit,_ ,_,_= model(graph.x, graph.edge_index, graph.batch,False,index_arr)\n",
    "            live_label = graph.y.float()\n",
    "            for i in range(len(logit)):\n",
    "                        scores_list.append(\"{} {}\\n\".format(logit[i].item(), live_label[i].item()))\n",
    "  # Check against ground-truth labels.\n",
    "    map_score_val_filename = os.path.join(score_path, \"score.txt\")\n",
    "    with open(map_score_val_filename, 'w') as file:\n",
    "                file.writelines(scores_list)\n",
    "    print(\"score: write test scores to {}\".format(map_score_val_filename))\n",
    "    test_ACC, fpr, FRR, HTER, auc_test, test_err, tpr = performances_val(map_score_val_filename)\n",
    "    print(\"epoch:{:d}, test:  val_ACC={:.4f}, HTER={:.4f}, AUC={:.4f}, val_err={:.4f}, ACC={:.4f}, TPR={:.4f}\".format(\n",
    "        epoch + 1, test_ACC, HTER, auc_test, test_err, test_ACC, tpr))  \n",
    "    return auc_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "135d749d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   8%|██▎                         | 273/3342 [00:48<07:38,  6.69batch/s]Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hassan-hossein/anaconda3/envs/Wav2Lip/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/hassan-hossein/anaconda3/envs/Wav2Lip/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/hassan-hossein/anaconda3/envs/Wav2Lip/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py\", line 28, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/hassan-hossein/anaconda3/envs/Wav2Lip/lib/python3.8/multiprocessing/queues.py\", line 116, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/hassan-hossein/anaconda3/envs/Wav2Lip/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 297, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/hassan-hossein/anaconda3/envs/Wav2Lip/lib/python3.8/multiprocessing/resource_sharer.py\", line 58, in detach\n",
      "    return reduction.recv_handle(conn)\n",
      "  File \"/home/hassan-hossein/anaconda3/envs/Wav2Lip/lib/python3.8/multiprocessing/reduction.py\", line 189, in recv_handle\n",
      "    return recvfds(s, 1)[0]\n",
      "  File \"/home/hassan-hossein/anaconda3/envs/Wav2Lip/lib/python3.8/multiprocessing/reduction.py\", line 157, in recvfds\n",
      "    msg, ancdata, flags, addr = sock.recvmsg(1, socket.CMSG_SPACE(bytes_size))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "Epoch 1:   8%|██▎                         | 273/3342 [00:48<09:07,  5.61batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# model.load_state_dict(torch.load(\"V_10_without_pipline_domain_generalization_tuning.pth\",map_location='cuda'))\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# best_auc = 0.9862\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# best_auc = 0\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m***************************\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#print(\"train : \")\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m#train_auc = test(train_loader,epoch)\u001b[39;00m\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m    291\u001b[0m loss_all \u001b[38;5;241m=\u001b[39m adv_loss \u001b[38;5;241m+\u001b[39m loss_cls \u001b[38;5;241m+\u001b[39m node_cls_loss\u001b[38;5;241m+\u001b[39mg_adv_loss\n\u001b[1;32m    292\u001b[0m loss_all\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Derive gradients.\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Update parameters based on gradients.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Clear gradients.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m loss_all \u001b[38;5;241m+\u001b[39m total_loss\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/site-packages/torch/optim/optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/site-packages/torch/optim/adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    155\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 157\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/site-packages/torch/optim/adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 213\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/site-packages/torch/optim/adam.py:263\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    262\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mmul_(beta1)\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m--> 263\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable:\n\u001b[1;32m    266\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(\"V_10_without_pipline_domain_generalization_tuning.pth\",map_location='cuda'))\n",
    "# best_auc = 0.9862\n",
    "# best_auc = 0\n",
    "for epoch in range(0, 1000):\n",
    "    train(epoch)\n",
    "    print(\"***************************\")\n",
    "    #print(\"train : \")\n",
    "    #train_auc = test(train_loader,epoch)\n",
    "    print(\"test : \")\n",
    "    test_auc = test(test_loader,epoch)\n",
    "    if test_auc > best_auc:\n",
    "        print(\"improve acc .. .. ..\")\n",
    "        torch.save(model.state_dict(), 'correct_V_10_without_pipline_domain_generalization_tuning.pth')\n",
    "        best_auc = test_auc\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "185459c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|███████████████████████████| 3342/3342 [10:50<00:00,  5.14batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(4.1702e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.0344e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(2.3682e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      " g_adv loss:  tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████████████| 349/349 [00:53<00:00,  6.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_1/score.txt\n",
      "epoch:1, test:  val_ACC=0.8134, HTER=0.1867, AUC=0.9044, val_err=0.1867, ACC=0.8134, TPR=0.5281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|███████████████████████████| 3342/3342 [08:30<00:00,  6.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.5884e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(1.8060e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      " g_adv loss:  tensor(7.2921e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████████████████████████████| 349/349 [00:50<00:00,  6.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_2/score.txt\n",
      "epoch:2, test:  val_ACC=0.8703, HTER=0.1297, AUC=0.9452, val_err=0.1297, ACC=0.8703, TPR=0.7870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|███████████████████████████| 3342/3342 [10:33<00:00,  5.27batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(5.5951e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(1.9578e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      " g_adv loss:  tensor(3.7967e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(6.3140e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████████████████████████████| 349/349 [00:50<00:00,  6.96batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_3/score.txt\n",
      "epoch:3, test:  val_ACC=0.8664, HTER=0.1336, AUC=0.9437, val_err=0.1336, ACC=0.8664, TPR=0.7996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|███████████████████████████| 3342/3342 [08:36<00:00,  6.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(5.2776e-12, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(7.0928e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(1.1389e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      " g_adv loss:  tensor(2.7720e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(4.6201e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|█████████████████████████████| 349/349 [00:50<00:00,  6.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_4/score.txt\n",
      "epoch:4, test:  val_ACC=0.8631, HTER=0.1369, AUC=0.9353, val_err=0.1369, ACC=0.8631, TPR=0.8039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5:  61%|████████████████▍          | 2028/3342 [07:00<04:32,  4.82batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# best_auc = 0\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m***************************\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#print(\"train : \")\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m#train_auc = test(train_loader,epoch)\u001b[39;00m\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m    292\u001b[0m loss_all \u001b[38;5;241m=\u001b[39m adv_loss \u001b[38;5;241m+\u001b[39m loss_cls \u001b[38;5;241m+\u001b[39m node_cls_loss\u001b[38;5;241m+\u001b[39mg_adv_loss\n\u001b[1;32m    293\u001b[0m loss_all\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Derive gradients.\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Update parameters based on gradients.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Clear gradients.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m loss_all \u001b[38;5;241m+\u001b[39m total_loss\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/site-packages/torch/optim/optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/site-packages/torch/optim/adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    155\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 157\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/site-packages/torch/optim/adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 213\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/site-packages/torch/optim/adam.py:305\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    303\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 305\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    307\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"V_10_without_pipline_domain_generalization_tuning.pth\",map_location='cuda'))\n",
    "best_auc = 0.9862\n",
    "# best_auc = 0\n",
    "for epoch in range(0, 1000):\n",
    "    train(epoch)\n",
    "    print(\"***************************\")\n",
    "    #print(\"train : \")\n",
    "    #train_auc = test(train_loader,epoch)\n",
    "    print(\"test : \")\n",
    "    test_auc = test(test_loader,epoch)\n",
    "    if test_auc > best_auc:\n",
    "        print(\"improve acc .. .. ..\")\n",
    "        torch.save(model.state_dict(), 'arg_contrast_bright_V_10_without_pipline_domain_generalization_tuning.pth')\n",
    "        best_auc = test_auc\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aded65da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   6%|█▉                            | 22/349 [00:05<01:25,  3.85batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(loader, epoch)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m :\n\u001b[1;32m    331\u001b[0m     index_arr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m29952\u001b[39m, (\u001b[38;5;241m64\u001b[39m,))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 333\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Move data to the device\u001b[39;00m\n\u001b[1;32m    334\u001b[0m logit,_ ,_,_\u001b[38;5;241m=\u001b[39m model(graph\u001b[38;5;241m.\u001b[39mx, graph\u001b[38;5;241m.\u001b[39medge_index, graph\u001b[38;5;241m.\u001b[39mbatch,\u001b[38;5;28;01mFalse\u001b[39;00m,index_arr)\n\u001b[1;32m    335\u001b[0m live_label \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/site-packages/torch_geometric/data/data.py:262\u001b[0m, in \u001b[0;36mBaseData.to\u001b[0;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    259\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/site-packages/torch_geometric/data/data.py:245\u001b[0m, in \u001b[0;36mBaseData.apply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstores:\n\u001b[0;32m--> 245\u001b[0m     \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/site-packages/torch_geometric/data/storage.py:184\u001b[0m, in \u001b[0;36mBaseStorage.apply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems(\u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m \u001b[43mrecursive_apply\u001b[49m(value, func)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test(test_loader,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e20c6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"arg_contrast_bright_V_10_without_pipline_domain_generalization_tuning.pth\",map_location='cuda'))\n",
    "best_auc = 0.9862"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95dd67d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████████████| 349/349 [00:48<00:00,  7.13batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_1/score.txt\n",
      "epoch:1, test:  val_ACC=0.9489, HTER=0.0511, AUC=0.9862, val_err=0.0511, ACC=0.9489, TPR=0.9482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9862148900258532"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(test_loader,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31a954c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fcb36c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 136334/136334 [04:11<00:00, 542.67it/s]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(glob.glob(\"/media/hassan-hossein/B660FEE360FEA8EF/oulu/preposess/*/patch*.npy\")):\n",
    "    os.system(\"rm -r \" + i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b1f0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Wav2Lip)",
   "language": "python",
   "name": "wav2lip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
