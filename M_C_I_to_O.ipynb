{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8632e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import GPUtil\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from focal_loss.focal_loss import FocalLoss\n",
    "\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import os\n",
    "from torch_geometric.data import Dataset, download_url\n",
    "from torch_geometric.loader import DataLoader\n",
    "import pandas as pd\n",
    "from performance import performances_val\n",
    "from PIL import Image\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "from torch_geometric.nn.norm import BatchNorm\n",
    "from torch_geometric.data import Data\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.nn import ChebConv, GraphSAGE,GraphUNet ,TransformerConv\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "seed = 1378\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "landmark_colors = np.load(\"landmark_colors.npy\")\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_list=[]\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(np.expand_dims(landmark_colors,axis=1))  \n",
    "for x in landmark_colors:\n",
    "    one_hot_list.append(enc.transform([[x]]).toarray()[0])\n",
    "one_hot_arr  = np.array(one_hot_list)\n",
    "one_hot_arr = torch.FloatTensor(one_hot_arr)\n",
    "\n",
    "m = torch.nn.Softmax(dim=-1)\n",
    "\n",
    "class landmark_dataset(Dataset):\n",
    "    def __init__(self, info_list, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(None, transform, pre_transform, pre_filter)\n",
    "        \n",
    "        self.graphs = pd.read_csv(info_list, delimiter=\",\", header=None)\n",
    "\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def get(self, idx):\n",
    "        \n",
    "        graph_path = self.graphs.iloc[idx]\n",
    "        graph_path = graph_path[0]\n",
    "        \n",
    "        \n",
    "        data = torch.load(graph_path)\n",
    "        #data.x =data.x.t()\n",
    "        return data \n",
    "class landmark_dataset_train(Dataset):\n",
    "    def __init__(self, info_list, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(None, transform, pre_transform, pre_filter)\n",
    "        \n",
    "        self.graphs = pd.read_csv(info_list, delimiter=\",\", header=None)\n",
    "\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def get(self, idx):\n",
    "        \n",
    "        graph_path = self.graphs.iloc[idx]\n",
    "        graph_path = graph_path[0]\n",
    "        \n",
    "        data = torch.load(graph_path)\n",
    "        \n",
    " \n",
    "        \n",
    "        domain_name = graph_path.split(\"/\")[-4]\n",
    "        \n",
    "            \n",
    "        if domain_name == \"MSU_MFSD\" :\n",
    "            \n",
    "            domain_label = 0\n",
    "            \n",
    "        elif domain_name == \"Replay_attack_dataset\" :\n",
    "            \n",
    "            domain_label = 1\n",
    "            \n",
    "        elif domain_name == \"casia-ds\" :\n",
    "            \n",
    "            domain_label = 2\n",
    "        else :\n",
    "            print(graph_path,domain_name )\n",
    "            raise \"error\"\n",
    "            \n",
    "        \n",
    "        data = Data(x=data.x, edge_index=data.edge_index,y =data.y,data = domain_label,y_node = one_hot_arr)\n",
    "\n",
    "        #data.x =data.x.t()\n",
    "        return data \n",
    "train_dataset = landmark_dataset_train(\"/home/hassan-hossein/single_image_graph_face_anti_spoofing/train/graph_train_M_C_I.txt\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True,num_workers=16,pin_memory=True)\n",
    "\n",
    "test_dataset = landmark_dataset(\"/home/hassan-hossein/single_image_graph_face_anti_spoofing/train/graph_test_O.txt\")\n",
    "test_loader = DataLoader(test_dataset, batch_size=64,num_workers=16)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "# فرض کنید که داده‌های ورودی شما یک توالی از ۶۸۰ ویژگی دارد.\n",
    "#sequence_length = 128\n",
    "#feature_dim = 4  # هر ویژگی تک‌بعدی است\n",
    "\n",
    "# نمونه داده ورودی (تعداد نمونه‌ها × طول توالی × بعد ویژگی)\n",
    "#inputs = torch.rand(32, sequence_length, feature_dim)  # 32 نمونه با 680 ویژگی تک‌بعدی\n",
    "\n",
    "# تعریف یک لایه ترنسفورمر انکودر\n",
    "class SimpleTransformer(nn.Module):\n",
    "    def __init__(self, embed_dim, num_layers, nhead,n_out):\n",
    "        super(SimpleTransformer, self).__init__()\n",
    "        self.linear = nn.Linear(4, embed_dim)  # افزایش بعد ویژگی‌ها\n",
    "        self.encoder_layer = TransformerEncoderLayer(d_model=embed_dim, nhead=nhead)\n",
    "        self.transformer_encoder = TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(128 * embed_dim, n_out)  # فرضا 10 کلاس خروجی داریم\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)  # تغییر بعد ویژگی‌ها\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.view(x.size(0), -1)  # فشرده‌سازی به یک بردار برای طبقه‌بندی\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# # ایجاد مدل و ارسال ورودی\n",
    "# # model = SimpleTransformer(embed_dim=embed_dim, num_layers=2, nhead=4)\n",
    "# # output = model(inputs)\n",
    "\n",
    "# #print(output.shape)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "# فرض کنید که داده‌های ورودی شما یک توالی از ۶۸۰ ویژگی دارد.\n",
    "sequence_length = 128\n",
    "feature_dim = 1  # هر ویژگی تک‌بعدی است\n",
    "\n",
    "# نمونه داده ورودی (تعداد نمونه‌ها × طول توالی × بعد ویژگی)\n",
    "#inputs = torch.rand(32, sequence_length, feature_dim)  # 32 نمونه با 680 ویژگی تک‌بعدی\n",
    "\n",
    "# تعریف یک لایه ترنسفورمر انکودر\n",
    "class SimpleTransformer_2(nn.Module):\n",
    "    def __init__(self, embed_dim, num_layers, nhead):\n",
    "        super(SimpleTransformer_2, self).__init__()\n",
    "        self.linear = nn.Linear(feature_dim, embed_dim)  # افزایش بعد ویژگی‌ها\n",
    "        self.encoder_layer = TransformerEncoderLayer(d_model=embed_dim, nhead=nhead)\n",
    "        self.transformer_encoder = TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(sequence_length * embed_dim, 7)  # فرضا 10 کلاس خروجی داریم\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)  # تغییر بعد ویژگی‌ها\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.view(x.size(0), -1)  # فشرده‌سازی به یک بردار برای طبقه‌بندی\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# # ایجاد مدل و ارسال ورودی\n",
    "# # model = SimpleTransformer(embed_dim=embed_dim, num_layers=2, nhead=4)\n",
    "# # output = model(inputs)\n",
    "\n",
    "# #print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc5eb386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): ChebConv(640, 128, K=2, normalization=sym)\n",
      "  (conv2): ChebConv(128, 128, K=2, normalization=sym)\n",
      "  (conv3): ChebConv(128, 128, K=2, normalization=sym)\n",
      "  (conv4): ChebConv(128, 128, K=2, normalization=sym)\n",
      "  (conv5): ChebConv(256, 128, K=2, normalization=sym)\n",
      "  (conv6): ChebConv(128, 128, K=2, normalization=sym)\n",
      "  (conv7): ChebConv(128, 128, K=2, normalization=sym)\n",
      "  (conv8): ChebConv(128, 128, K=2, normalization=sym)\n",
      "  (lin): SimpleTransformer(\n",
      "    (linear): Linear(in_features=4, out_features=8, bias=True)\n",
      "    (encoder_layer): TransformerEncoderLayer(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "      )\n",
      "      (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "      (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Linear(in_features=1024, out_features=1, bias=True)\n",
      "  )\n",
      "  (drop_1): RandomNodeDropout()\n",
      "  (drop_2): RandomNodeDropout()\n",
      "  (drop_3): RandomNodeDropout()\n",
      "  (drop_4): RandomNodeDropout()\n",
      "  (drop_5): RandomNodeDropout()\n",
      "  (drop_6): RandomNodeDropout()\n",
      "  (b1): BatchNorm(128)\n",
      "  (b2): BatchNorm(128)\n",
      "  (b3): BatchNorm(128)\n",
      "  (b4): BatchNorm(128)\n",
      "  (b5): BatchNorm(128)\n",
      "  (b6): BatchNorm(128)\n",
      "  (b7): BatchNorm(128)\n",
      "  (dis): Discriminator(\n",
      "    (conv1): GraphSAGE(128, 128, num_layers=2)\n",
      "    (conv2): GraphSAGE(128, 128, num_layers=2)\n",
      "    (conv3): GraphSAGE(128, 128, num_layers=2)\n",
      "    (conv4): GraphSAGE(128, 128, num_layers=2)\n",
      "    (drop_1): RandomNodeDropout()\n",
      "    (drop_2): RandomNodeDropout()\n",
      "    (grl_layer): GRL()\n",
      "    (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (conv1_node_class): GraphSAGE(128, 128, num_layers=2)\n",
      "  (conv2_node_class): GraphSAGE(128, 128, num_layers=2)\n",
      "  (lin_node_class): SimpleTransformer_2(\n",
      "    (linear): Linear(in_features=1, out_features=64, bias=True)\n",
      "    (encoder_layer): TransformerEncoderLayer(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "      (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (6): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (7): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (8): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (9): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Linear(in_features=8192, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class RandomNodeDropout(nn.Module):\n",
    "    def __init__(self, drop_prob=0.3):\n",
    "        super(RandomNodeDropout, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x, enabled=True):\n",
    "        if not self.training or not enabled:\n",
    "            return x\n",
    "        \n",
    "        num_rows = x.size(0)\n",
    "        mask = torch.rand(num_rows, device=x.device) > self.drop_prob\n",
    "        mask = mask.float().unsqueeze(1).expand_as(x)\n",
    "        x = x * mask\n",
    "        \n",
    "        return x\n",
    "\n",
    "soft = torch.nn.Softmax(dim=1)\n",
    "\n",
    "num_domain = 3\n",
    "class GRL(nn.Module):\n",
    "\n",
    "    def __init__(self, max_iter):\n",
    "        super(GRL, self).__init__()\n",
    "        self.iter_num = 0\n",
    "        self.alpha = 10\n",
    "        self.low = 0.0\n",
    "        self.high = 1.0\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.iter_num += 1\n",
    "        return input * 1.0\n",
    "\n",
    "    def backward(self, gradOutput):\n",
    "        coeff = np.float(2.0 * (self.high - self.low) / (1.0 + np.exp(-self.alpha * self.iter_num / self.max_iter))\n",
    "                         - (self.high - self.low) + self.low)\n",
    "        return -coeff*10* gradOutput\n",
    "\n",
    "num_node  =train_dataset.num_node_features\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self,hidden_channels ,max_iter):\n",
    "        super(Discriminator, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GraphSAGE(hidden_channels, hidden_channels,2,dropout=0.5)\n",
    "        self.conv2 = GraphSAGE(hidden_channels, hidden_channels,2,dropout=0.5)\n",
    "        self.conv3 = GraphSAGE(hidden_channels, hidden_channels,2,dropout=0.5)\n",
    "        self.conv4 = GraphSAGE(hidden_channels, hidden_channels,2,dropout=0.5)\n",
    "        self.drop_1 = RandomNodeDropout(drop_prob=0.3)\n",
    "        self.drop_2 = RandomNodeDropout(drop_prob=0.3)\n",
    "        self.grl_layer = GRL(max_iter)\n",
    "        self.fc2 = nn.Linear(hidden_channels, num_domain)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch,drop_en):\n",
    "        #print(\"graph fea :\",graph_level_feature.shape ,edge_index.shape )\n",
    "        \n",
    "        x = self.grl_layer(x)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.drop_1(x,drop_en)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.drop_2(x,drop_en)\n",
    "        \n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = m(x)\n",
    "         \n",
    "        return x \n",
    "\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels,max_iter=4000):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = ChebConv(num_node, hidden_channels,2)\n",
    "        self.conv2 = ChebConv(hidden_channels, hidden_channels,2)\n",
    "        self.conv3 = ChebConv(hidden_channels, hidden_channels,2)\n",
    "        self.conv4 = ChebConv(hidden_channels, hidden_channels,2)\n",
    "        self.conv5 = ChebConv(hidden_channels*2, hidden_channels,2)\n",
    "        self.conv6 = ChebConv(hidden_channels, hidden_channels,2)\n",
    "        self.conv7 = ChebConv(hidden_channels, hidden_channels,2)\n",
    "        self.conv8 = ChebConv(hidden_channels, hidden_channels,2)\n",
    "        self.lin = SimpleTransformer(8,5,8,1)\n",
    "        \n",
    "        self.drop_1 = RandomNodeDropout(drop_prob=0.3)\n",
    "        self.drop_2 = RandomNodeDropout(drop_prob=0.3)\n",
    "        self.drop_3 = RandomNodeDropout(drop_prob=0.3)\n",
    "        self.drop_4 = RandomNodeDropout(drop_prob=0.3)\n",
    "        self.drop_5 = RandomNodeDropout(drop_prob=0.3)\n",
    "        self.drop_6 = RandomNodeDropout(drop_prob=0.3)\n",
    "        \n",
    "        \n",
    "        self.b1 = BatchNorm(hidden_channels)\n",
    "        self.b2 = BatchNorm(hidden_channels)\n",
    "        self.b3 = BatchNorm(hidden_channels)\n",
    "        self.b4 = BatchNorm(hidden_channels)\n",
    "        self.b5 = BatchNorm(hidden_channels)\n",
    "        self.b6 = BatchNorm(hidden_channels)\n",
    "        self.b7 = BatchNorm(hidden_channels)\n",
    "        \n",
    "        self.dis = Discriminator(hidden_channels,max_iter)\n",
    "        \n",
    "        self.conv1_node_class = GraphSAGE(hidden_channels, hidden_channels,2,dropout=0.5)\n",
    "        \n",
    "        self.conv2_node_class = GraphSAGE(hidden_channels, hidden_channels,2,dropout=0.5)\n",
    "        \n",
    "        self.lin_node_class = SimpleTransformer_2(64,10,8)\n",
    "        \n",
    "\n",
    "        \n",
    "        #self.tcn = Simple1DCNN()\n",
    "        \n",
    "    def forward(self, x, edge_index, batch,drop_en,index_arr):\n",
    "        #print(\"graph fea :\",graph_level_feature.shape ,edge_index.shape )\n",
    "        \n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x  = self.b1(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = self.drop_1(x,drop_en)\n",
    "        \n",
    "        \n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x  = self.b2(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = self.drop_2(x,drop_en)\n",
    "                \n",
    "        dicriminator = x\n",
    "        \n",
    "        x_1 = global_mean_pool(x, batch)\n",
    "        \n",
    "        x = self.conv3(x, edge_index)\n",
    "        x  = self.b3(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = self.drop_3(x,drop_en)\n",
    "        \n",
    "        x_3 = global_mean_pool(x, batch)\n",
    "        \n",
    "        \n",
    "        x = self.conv4(x, edge_index)\n",
    "        x  = self.b4(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = self.drop_4(x,drop_en)\n",
    "        \n",
    "        \n",
    "        x = torch.cat((x,dicriminator),dim=1) #skip connection\n",
    "        \n",
    "        x = self.conv5(x, edge_index)\n",
    "        x  = self.b5(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = self.drop_5(x,drop_en)\n",
    "        \n",
    "        x_5 = global_mean_pool(x, batch)\n",
    "        \n",
    "        x = self.conv6(x, edge_index)\n",
    "        x  = self.b6(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = self.drop_6(x,drop_en)\n",
    "        \n",
    "        x = self.conv7(x, edge_index)\n",
    "        x  = self.b7(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        \n",
    "        x = self.conv8(x, edge_index)\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "        \n",
    "        x = torch.stack([x,x_1,x_5,x_3],dim=2)\n",
    "        \n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        \n",
    "        #x = torch.unsqueeze(x,2)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        x = self.lin(x)\n",
    "        \n",
    "        x= x.sigmoid()\n",
    "        \n",
    "        \n",
    "        node_class_hidden = self.conv1_node_class(dicriminator,edge_index)\n",
    "        node_class_hidden = node_class_hidden.relu()\n",
    "        \n",
    "        node_class_hidden = self.conv2_node_class(node_class_hidden,edge_index)\n",
    "        node_class_hidden = node_class_hidden.relu()\n",
    "        \n",
    "        #print(index_arr.shape , node_class_hidden.shape)\n",
    "        \n",
    "        node_class_hidden = node_class_hidden[index_arr]\n",
    "        \n",
    "        #print(node_class_hidden.shape)\n",
    "        node_class_hidden = torch.unsqueeze(node_class_hidden, dim=2)\n",
    "        \n",
    "        node_pre = self.lin_node_class(node_class_hidden)\n",
    "        \n",
    "            \n",
    "        #print(\"hiiii :\" , dicriminator.shape)\n",
    "        dis_invariant = self.dis(dicriminator,edge_index,batch,drop_en)\n",
    "        \n",
    "        return x ,dis_invariant ,node_pre\n",
    "\n",
    "model = GCN(hidden_channels=128).to(device)\n",
    "print(model)\n",
    "\n",
    "def check_folder(log_dir):\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    return log_dir\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion= nn.BCELoss()\n",
    "criterion_node_class=  torch.nn.CrossEntropyLoss()\n",
    "criterion_2 = FocalLoss(gamma=2)\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    losses_adv_loss=0\n",
    "    losses_loss_cls=0\n",
    "    total_loss = 0\n",
    "    losses_node_cls_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}', unit='batch')\n",
    "    for graph in progress_bar:  # Iterate in batches over the training dataset.\n",
    "        graph = graph.to(device)  # Move data to the device\n",
    "        \n",
    "        drop_en = bool(np.random.binomial(1, 0.5))\n",
    "        \n",
    "        if graph.x.shape[0] < 29952 :\n",
    "            \n",
    "            if graph.x.shape[0] < 64:\n",
    "            \n",
    "                index_arr = torch.randint(0, int(graph.x.shape[0]), (int(graph.x.shape[0]),)).to(device)\n",
    "            else :\n",
    "                \n",
    "                index_arr = torch.randint(0, int(graph.x.shape[0]), (64,)).to(device)\n",
    "        else :\n",
    "                \n",
    "            index_arr = torch.randint(0, 29952, (64,)).to(device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        out,domain_invariant,node_pre = model(graph.x, graph.edge_index, graph.batch,drop_en,index_arr)  # Perform a single forward pass.\n",
    "        \n",
    "        adv_loss = criterion_2(domain_invariant, graph.data)\n",
    "        \n",
    "        node_cls_loss = criterion_node_class(node_pre.squeeze(),graph.y_node.float()[index_arr])\n",
    "        #print(out.shape , graph.y.long().shape)\n",
    "        loss_cls = criterion(out.squeeze(), graph.y.float())  # Compute the loss.\n",
    "        \n",
    "        loss_all = adv_loss + loss_cls + node_cls_loss\n",
    "        loss_all.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "        total_loss = loss_all + total_loss\n",
    "        losses_adv_loss = adv_loss + losses_adv_loss\n",
    "        losses_loss_cls = loss_cls + losses_loss_cls\n",
    "        losses_node_cls_loss = node_cls_loss + losses_node_cls_loss\n",
    "\n",
    "\n",
    "    print(\"/////////////////////////\")\n",
    "    print(\"adverserial loss : \" ,losses_adv_loss/len(train_loader.dataset))  \n",
    "    print(\"classification loss : \" , losses_loss_cls/len(train_loader.dataset))\n",
    "    print(\"classification node loss : \" , losses_node_cls_loss/len(train_loader.dataset))\n",
    "    print(\"total loss : \" ,total_loss/len(train_loader.dataset) )\n",
    "    print(\"////////////////////////////////////\")\n",
    "def test(loader,epoch):\n",
    "    score_path = os.path.join(\"/home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores\", \"epoch_{}\".format(epoch+1))\n",
    "    check_folder(score_path)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        scores_list = []\n",
    "\n",
    "        correct = 0\n",
    "        s= 0\n",
    "        progress_bar = tqdm(loader, desc=f'Epoch {epoch+1}', unit='batch')\n",
    "        for graph in progress_bar:  # Iterate in batches over the training/test dataset.\n",
    "            if graph.x.shape[0] < 29952 :\n",
    "\n",
    "                if graph.x.shape[0] < 64:\n",
    "\n",
    "                    index_arr = torch.randint(0, int(graph.x.shape[0]), (int(graph.x.shape[0]),)).to(device)\n",
    "                else :\n",
    "\n",
    "                    index_arr = torch.randint(0, int(graph.x.shape[0]), (64,)).to(device)\n",
    "            else :\n",
    "\n",
    "                index_arr = torch.randint(0, 29952, (64,)).to(device)\n",
    "                \n",
    "            graph = graph.to(device)  # Move data to the device\n",
    "            logit,_ ,_= model(graph.x, graph.edge_index, graph.batch,False,index_arr)\n",
    "            live_label = graph.y.float()\n",
    "            for i in range(len(logit)):\n",
    "                        scores_list.append(\"{} {}\\n\".format(logit[i].item(), live_label[i].item()))\n",
    "  # Check against ground-truth labels.\n",
    "    map_score_val_filename = os.path.join(score_path, \"score.txt\")\n",
    "    with open(map_score_val_filename, 'w') as file:\n",
    "                file.writelines(scores_list)\n",
    "    print(\"score: write test scores to {}\".format(map_score_val_filename))\n",
    "    test_ACC, fpr, FRR, HTER, auc_test, test_err, tpr = performances_val(map_score_val_filename)\n",
    "    print(\"epoch:{:d}, test:  val_ACC={:.4f}, HTER={:.4f}, AUC={:.4f}, val_err={:.4f}, ACC={:.4f}, TPR={:.4f}\".format(\n",
    "        epoch + 1, test_ACC, HTER, auc_test, test_err, test_ACC, tpr))  \n",
    "    return auc_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b41fe22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|████████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [04:55<00:00,  5.28batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|████████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [13:47<00:00,  2.58batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_1/score.txt\n",
      "epoch:1, test:  val_ACC=0.8128, HTER=0.1894, AUC=0.8713, val_err=0.1890, ACC=0.8128, TPR=0.0789\n",
      "improve acc .. .. ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|████████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [05:36<00:00,  4.64batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(6.3977e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|████████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [13:01<00:00,  2.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_2/score.txt\n",
      "epoch:2, test:  val_ACC=0.8421, HTER=0.1579, AUC=0.9184, val_err=0.1580, ACC=0.8421, TPR=0.5325\n",
      "improve acc .. .. ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|████████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [06:19<00:00,  4.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(3.8784e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(6.7762e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|████████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [12:00<00:00,  2.96batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_3/score.txt\n",
      "epoch:3, test:  val_ACC=0.9727, HTER=0.1578, AUC=0.8811, val_err=0.1777, ACC=0.9727, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [06:51<00:00,  3.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(3.3048e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(5.3068e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [11:14<00:00,  3.16batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_4/score.txt\n",
      "epoch:4, test:  val_ACC=0.9983, HTER=0.2357, AUC=0.7650, val_err=0.4630, ACC=0.9983, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|████████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [07:25<00:00,  3.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(4.5487e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.2423e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|████████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [11:11<00:00,  3.18batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_5/score.txt\n",
      "epoch:5, test:  val_ACC=0.9917, HTER=0.2363, AUC=0.7692, val_err=0.4307, ACC=0.9917, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|████████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [07:52<00:00,  3.30batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(2.2900e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.3404e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|████████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [10:44<00:00,  3.31batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_6/score.txt\n",
      "epoch:6, test:  val_ACC=0.9981, HTER=0.2484, AUC=0.7522, val_err=0.4870, ACC=0.9981, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|████████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [08:15<00:00,  3.15batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.7118e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(2.1679e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|████████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [10:34<00:00,  3.36batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_7/score.txt\n",
      "epoch:7, test:  val_ACC=0.8838, HTER=0.1170, AUC=0.9342, val_err=0.1167, ACC=0.8838, TPR=0.8243\n",
      "improve acc .. .. ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|████████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [08:47<00:00,  2.96batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.7955e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(2.6608e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|████████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [10:00<00:00,  3.55batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_8/score.txt\n",
      "epoch:8, test:  val_ACC=0.9972, HTER=0.2459, AUC=0.7556, val_err=0.4775, ACC=0.9972, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|████████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [09:06<00:00,  2.85batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(7.1089e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(2.5263e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|████████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [09:27<00:00,  3.75batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_9/score.txt\n",
      "epoch:9, test:  val_ACC=0.9991, HTER=0.3327, AUC=0.6676, val_err=0.6611, ACC=0.9991, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [09:30<00:00,  2.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(2.1190e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.3321e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [09:03<00:00,  3.92batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_10/score.txt\n",
      "epoch:10, test:  val_ACC=0.8645, HTER=0.1356, AUC=0.9391, val_err=0.1355, ACC=0.8645, TPR=0.6363\n",
      "improve acc .. .. ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [09:52<00:00,  2.63batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(7.7806e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.1459e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [08:22<00:00,  4.24batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_11/score.txt\n",
      "epoch:11, test:  val_ACC=0.9917, HTER=0.1437, AUC=0.8664, val_err=0.2455, ACC=0.9917, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [10:10<00:00,  2.55batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.1003e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(2.7824e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [08:10<00:00,  4.34batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_12/score.txt\n",
      "epoch:12, test:  val_ACC=0.9927, HTER=0.1538, AUC=0.8533, val_err=0.2704, ACC=0.9927, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [10:27<00:00,  2.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.1466e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.8049e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [07:48<00:00,  4.55batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_13/score.txt\n",
      "epoch:13, test:  val_ACC=0.9926, HTER=0.1435, AUC=0.8654, val_err=0.2495, ACC=0.9926, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [10:38<00:00,  2.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(5.5253e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.0234e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [07:33<00:00,  4.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_14/score.txt\n",
      "epoch:14, test:  val_ACC=0.9876, HTER=0.1450, AUC=0.8707, val_err=0.2272, ACC=0.9876, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [10:31<00:00,  2.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(2.6873e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.0496e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [07:47<00:00,  4.55batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_15/score.txt\n",
      "epoch:15, test:  val_ACC=0.9965, HTER=0.2063, AUC=0.7966, val_err=0.3949, ACC=0.9965, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [10:50<00:00,  2.40batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(4.2155e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.7180e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [07:23<00:00,  4.81batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_16/score.txt\n",
      "epoch:16, test:  val_ACC=0.9979, HTER=0.2050, AUC=0.7967, val_err=0.3995, ACC=0.9979, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [10:56<00:00,  2.38batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(5.0196e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.8436e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [07:33<00:00,  4.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_17/score.txt\n",
      "epoch:17, test:  val_ACC=0.9984, HTER=0.3025, AUC=0.6982, val_err=0.5970, ACC=0.9984, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [11:05<00:00,  2.34batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(6.9903e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.7923e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [07:48<00:00,  4.55batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_18/score.txt\n",
      "epoch:18, test:  val_ACC=0.9861, HTER=0.1392, AUC=0.8804, val_err=0.2080, ACC=0.9861, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [10:52<00:00,  2.39batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(5.9890e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(2.1525e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [07:38<00:00,  4.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_19/score.txt\n",
      "epoch:19, test:  val_ACC=0.9952, HTER=0.2064, AUC=0.7976, val_err=0.3885, ACC=0.9952, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [10:54<00:00,  2.38batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(5.0094e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(8.3456e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [07:52<00:00,  4.51batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_20/score.txt\n",
      "epoch:20, test:  val_ACC=0.9975, HTER=0.2415, AUC=0.7599, val_err=0.4703, ACC=0.9975, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [10:52<00:00,  2.39batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(5.2246e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(2.4995e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [07:40<00:00,  4.62batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_21/score.txt\n",
      "epoch:21, test:  val_ACC=0.9933, HTER=0.1877, AUC=0.8175, val_err=0.3417, ACC=0.9933, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [10:34<00:00,  2.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(2.5659e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.0245e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [08:34<00:00,  4.14batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_22/score.txt\n",
      "epoch:22, test:  val_ACC=0.9972, HTER=0.2151, AUC=0.7860, val_err=0.4162, ACC=0.9972, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [10:10<00:00,  2.56batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(5.7258e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.0377e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [09:02<00:00,  3.93batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_23/score.txt\n",
      "epoch:23, test:  val_ACC=0.9944, HTER=0.2129, AUC=0.7914, val_err=0.3976, ACC=0.9944, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [09:34<00:00,  2.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(3.2979e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(9.6553e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [09:47<00:00,  3.63batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_24/score.txt\n",
      "epoch:24, test:  val_ACC=0.9934, HTER=0.1547, AUC=0.8526, val_err=0.2763, ACC=0.9934, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [08:54<00:00,  2.92batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(2.9258e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.8801e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [10:19<00:00,  3.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_25/score.txt\n",
      "epoch:25, test:  val_ACC=0.9913, HTER=0.1295, AUC=0.8810, val_err=0.2149, ACC=0.9913, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [08:25<00:00,  3.08batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(2.5580e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(6.1332e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [11:05<00:00,  3.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_26/score.txt\n",
      "epoch:26, test:  val_ACC=0.9778, HTER=0.1386, AUC=0.8953, val_err=0.1646, ACC=0.9778, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [07:49<00:00,  3.32batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(6.4123e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.3740e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [11:35<00:00,  3.07batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_27/score.txt\n",
      "epoch:27, test:  val_ACC=0.9970, HTER=0.2746, AUC=0.7271, val_err=0.5342, ACC=0.9970, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [07:04<00:00,  3.67batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(2.4124e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(2.0845e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [12:07<00:00,  2.93batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_28/score.txt\n",
      "epoch:28, test:  val_ACC=0.9911, HTER=0.2164, AUC=0.7911, val_err=0.3877, ACC=0.9911, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [06:31<00:00,  3.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(4.6992e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(7.9251e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [13:02<00:00,  2.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_29/score.txt\n",
      "epoch:29, test:  val_ACC=0.9988, HTER=0.3071, AUC=0.6930, val_err=0.6079, ACC=0.9988, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [05:49<00:00,  4.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(4.0160e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.2906e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [13:33<00:00,  2.62batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_30/score.txt\n",
      "epoch:30, test:  val_ACC=0.9982, HTER=0.2768, AUC=0.7238, val_err=0.5447, ACC=0.9982, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [05:00<00:00,  5.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(4.2411e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.6080e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [05:21<00:00,  6.62batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_31/score.txt\n",
      "epoch:31, test:  val_ACC=0.9987, HTER=0.2663, AUC=0.7345, val_err=0.5258, ACC=0.9987, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [04:50<00:00,  5.38batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(5.7246e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(6.6925e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [13:13<00:00,  2.69batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_32/score.txt\n",
      "epoch:32, test:  val_ACC=0.9980, HTER=0.2263, AUC=0.7751, val_err=0.4423, ACC=0.9980, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [05:09<00:00,  5.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(3.6031e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.0652e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [13:25<00:00,  2.64batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_33/score.txt\n",
      "epoch:33, test:  val_ACC=0.9977, HTER=0.2248, AUC=0.7762, val_err=0.4376, ACC=0.9977, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [05:46<00:00,  4.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(3.3710e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.3419e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [12:32<00:00,  2.83batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_34/score.txt\n",
      "epoch:34, test:  val_ACC=0.9968, HTER=0.2034, AUC=0.7989, val_err=0.3908, ACC=0.9968, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [06:18<00:00,  4.12batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(6.8523e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(5.2677e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [12:03<00:00,  2.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_35/score.txt\n",
      "epoch:35, test:  val_ACC=0.9994, HTER=0.3472, AUC=0.6529, val_err=0.6913, ACC=0.9994, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [06:52<00:00,  3.78batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(8.6115e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(8.1013e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [11:28<00:00,  3.09batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_36/score.txt\n",
      "epoch:36, test:  val_ACC=0.9981, HTER=0.2253, AUC=0.7759, val_err=0.4408, ACC=0.9981, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [07:22<00:00,  3.52batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(3.8568e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.6882e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [11:00<00:00,  3.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_37/score.txt\n",
      "epoch:37, test:  val_ACC=0.9918, HTER=0.1818, AUC=0.8265, val_err=0.3219, ACC=0.9918, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [07:59<00:00,  3.25batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(4.0150e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.9223e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [10:37<00:00,  3.34batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_38/score.txt\n",
      "epoch:38, test:  val_ACC=0.9985, HTER=0.2425, AUC=0.7581, val_err=0.4774, ACC=0.9985, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [08:21<00:00,  3.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(2.8604e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(8.7778e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [09:56<00:00,  3.58batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_39/score.txt\n",
      "epoch:39, test:  val_ACC=0.9966, HTER=0.1700, AUC=0.8321, val_err=0.3226, ACC=0.9966, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [08:49<00:00,  2.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(3.4113e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.3746e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [09:25<00:00,  3.77batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_40/score.txt\n",
      "epoch:40, test:  val_ACC=0.9793, HTER=0.1384, AUC=0.8922, val_err=0.1722, ACC=0.9793, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [09:15<00:00,  2.81batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(3.8531e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(4.4616e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [09:11<00:00,  3.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_41/score.txt\n",
      "epoch:41, test:  val_ACC=0.9961, HTER=0.2360, AUC=0.7659, val_err=0.4523, ACC=0.9961, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|███████████████████████████████████████████████████████████████████████████████████████| 1560/1560 [12:14<00:00,  2.12batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.2304e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.8319e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [10:49<00:00,  3.28batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_42/score.txt\n",
      "epoch:42, test:  val_ACC=0.9953, HTER=0.2233, AUC=0.7803, val_err=0.4230, ACC=0.9953, TPR=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43:   7%|██████▍                                                                                 | 114/1560 [00:27<05:42,  4.22batch/s]\n"
     ]
    }
   ],
   "source": [
    "best_auc = 0\n",
    "for epoch in range(0, 1000):\n",
    "    train(epoch)\n",
    "    print(\"***************************\")\n",
    "    #print(\"train : \")\n",
    "    #train_auc = test(train_loader,epoch)\n",
    "    print(\"test : \")\n",
    "    test_auc = test(test_loader,epoch)\n",
    "    if test_auc > best_auc:\n",
    "        print(\"improve acc .. .. ..\")\n",
    "        torch.save(model.state_dict(), 'Focal_without_pipline_domain_generalization_tuning_for_I.pth')\n",
    "        best_auc = test_auc\n",
    "        continue  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dec46a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): ChebConv(640, 128, K=2, normalization=sym)\n",
      "  (conv2): ChebConv(128, 128, K=2, normalization=sym)\n",
      "  (conv3): ChebConv(128, 128, K=2, normalization=sym)\n",
      "  (conv4): ChebConv(128, 128, K=2, normalization=sym)\n",
      "  (conv5): ChebConv(256, 128, K=2, normalization=sym)\n",
      "  (conv6): ChebConv(128, 128, K=2, normalization=sym)\n",
      "  (conv7): ChebConv(128, 128, K=2, normalization=sym)\n",
      "  (conv8): ChebConv(128, 128, K=2, normalization=sym)\n",
      "  (lin): SimpleTransformer(\n",
      "    (linear): Linear(in_features=4, out_features=8, bias=True)\n",
      "    (encoder_layer): TransformerEncoderLayer(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "      )\n",
      "      (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "      (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
      "  )\n",
      "  (drop_1): RandomNodeDropout()\n",
      "  (drop_2): RandomNodeDropout()\n",
      "  (drop_3): RandomNodeDropout()\n",
      "  (drop_4): RandomNodeDropout()\n",
      "  (drop_5): RandomNodeDropout()\n",
      "  (drop_6): RandomNodeDropout()\n",
      "  (b1): BatchNorm(128)\n",
      "  (b2): BatchNorm(128)\n",
      "  (b3): BatchNorm(128)\n",
      "  (b4): BatchNorm(128)\n",
      "  (b5): BatchNorm(128)\n",
      "  (b6): BatchNorm(128)\n",
      "  (b7): BatchNorm(128)\n",
      "  (dis): Discriminator(\n",
      "    (conv1): GraphSAGE(128, 128, num_layers=2)\n",
      "    (conv2): GraphSAGE(128, 128, num_layers=2)\n",
      "    (conv3): GraphSAGE(128, 128, num_layers=2)\n",
      "    (conv4): GraphSAGE(128, 128, num_layers=2)\n",
      "    (drop_1): RandomNodeDropout()\n",
      "    (drop_2): RandomNodeDropout()\n",
      "    (grl_layer): GRL()\n",
      "    (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (conv1_node_class): GraphSAGE(128, 128, num_layers=2)\n",
      "  (conv2_node_class): GraphSAGE(128, 128, num_layers=2)\n",
      "  (lin_node_class): SimpleTransformer_2(\n",
      "    (linear): Linear(in_features=1, out_features=64, bias=True)\n",
      "    (encoder_layer): TransformerEncoderLayer(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "      (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (6): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (7): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (8): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (9): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Linear(in_features=8192, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class RandomNodeDropout(nn.Module):\n",
    "    def __init__(self, drop_prob=0.3):\n",
    "        super(RandomNodeDropout, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x, enabled=True):\n",
    "        if not self.training or not enabled:\n",
    "            return x\n",
    "        \n",
    "        num_rows = x.size(0)\n",
    "        mask = torch.rand(num_rows, device=x.device) > self.drop_prob\n",
    "        mask = mask.float().unsqueeze(1).expand_as(x)\n",
    "        x = x * mask\n",
    "        \n",
    "        return x\n",
    "\n",
    "soft = torch.nn.Softmax(dim=1)\n",
    "\n",
    "num_domain = 3\n",
    "class GRL(nn.Module):\n",
    "\n",
    "    def __init__(self, max_iter):\n",
    "        super(GRL, self).__init__()\n",
    "        self.iter_num = 0\n",
    "        self.alpha = 10\n",
    "        self.low = 0.0\n",
    "        self.high = 1.0\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.iter_num += 1\n",
    "        return input * 1.0\n",
    "\n",
    "    def backward(self, gradOutput):\n",
    "        coeff = np.float(2.0 * (self.high - self.low) / (1.0 + np.exp(-self.alpha * self.iter_num / self.max_iter))\n",
    "                         - (self.high - self.low) + self.low)\n",
    "        return -coeff*10* gradOutput\n",
    "\n",
    "num_node  =train_dataset.num_node_features\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self,hidden_channels ,max_iter):\n",
    "        super(Discriminator, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GraphSAGE(hidden_channels, hidden_channels,2,dropout=0.5)\n",
    "        self.conv2 = GraphSAGE(hidden_channels, hidden_channels,2,dropout=0.5)\n",
    "        self.conv3 = GraphSAGE(hidden_channels, hidden_channels,2,dropout=0.5)\n",
    "        self.conv4 = GraphSAGE(hidden_channels, hidden_channels,2,dropout=0.5)\n",
    "        self.drop_1 = RandomNodeDropout(drop_prob=0.3)\n",
    "        self.drop_2 = RandomNodeDropout(drop_prob=0.3)\n",
    "        self.grl_layer = GRL(max_iter)\n",
    "        self.fc2 = nn.Linear(hidden_channels, num_domain)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch,drop_en):\n",
    "        #print(\"graph fea :\",graph_level_feature.shape ,edge_index.shape )\n",
    "        \n",
    "        x = self.grl_layer(x)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.drop_1(x,drop_en)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.drop_2(x,drop_en)\n",
    "        \n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = m(x)\n",
    "         \n",
    "        return x \n",
    "\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels,max_iter=4000):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = ChebConv(num_node, hidden_channels,2)\n",
    "        self.conv2 = ChebConv(hidden_channels, hidden_channels,2)\n",
    "        self.conv3 = ChebConv(hidden_channels, hidden_channels,2)\n",
    "        self.conv4 = ChebConv(hidden_channels, hidden_channels,2)\n",
    "        self.conv5 = ChebConv(hidden_channels*2, hidden_channels,2)\n",
    "        self.conv6 = ChebConv(hidden_channels, hidden_channels,2)\n",
    "        self.conv7 = ChebConv(hidden_channels, hidden_channels,2)\n",
    "        self.conv8 = ChebConv(hidden_channels, hidden_channels,2)\n",
    "        self.lin = SimpleTransformer(8,5,8,2)\n",
    "        \n",
    "        self.drop_1 = RandomNodeDropout(drop_prob=0.3)\n",
    "        self.drop_2 = RandomNodeDropout(drop_prob=0.3)\n",
    "        self.drop_3 = RandomNodeDropout(drop_prob=0.3)\n",
    "        self.drop_4 = RandomNodeDropout(drop_prob=0.3)\n",
    "        self.drop_5 = RandomNodeDropout(drop_prob=0.3)\n",
    "        self.drop_6 = RandomNodeDropout(drop_prob=0.3)\n",
    "        \n",
    "        \n",
    "        self.b1 = BatchNorm(hidden_channels)\n",
    "        self.b2 = BatchNorm(hidden_channels)\n",
    "        self.b3 = BatchNorm(hidden_channels)\n",
    "        self.b4 = BatchNorm(hidden_channels)\n",
    "        self.b5 = BatchNorm(hidden_channels)\n",
    "        self.b6 = BatchNorm(hidden_channels)\n",
    "        self.b7 = BatchNorm(hidden_channels)\n",
    "        \n",
    "        self.dis = Discriminator(hidden_channels,max_iter)\n",
    "        \n",
    "        self.conv1_node_class = GraphSAGE(hidden_channels, hidden_channels,2,dropout=0.5)\n",
    "        \n",
    "        self.conv2_node_class = GraphSAGE(hidden_channels, hidden_channels,2,dropout=0.5)\n",
    "        \n",
    "        self.lin_node_class = SimpleTransformer_2(64,10,8)\n",
    "        \n",
    "\n",
    "        \n",
    "        #self.tcn = Simple1DCNN()\n",
    "        \n",
    "    def forward(self, x, edge_index, batch,drop_en,index_arr):\n",
    "        #print(\"graph fea :\",graph_level_feature.shape ,edge_index.shape )\n",
    "        \n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x  = self.b1(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = self.drop_1(x,drop_en)\n",
    "        \n",
    "        \n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x  = self.b2(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = self.drop_2(x,drop_en)\n",
    "                \n",
    "        dicriminator = x\n",
    "        \n",
    "        x_1 = global_mean_pool(x, batch)\n",
    "        \n",
    "        x = self.conv3(x, edge_index)\n",
    "        x  = self.b3(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = self.drop_3(x,drop_en)\n",
    "        \n",
    "        x_3 = global_mean_pool(x, batch)\n",
    "        \n",
    "        \n",
    "        x = self.conv4(x, edge_index)\n",
    "        x  = self.b4(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = self.drop_4(x,drop_en)\n",
    "        \n",
    "        \n",
    "        x = torch.cat((x,dicriminator),dim=1) #skip connection\n",
    "        \n",
    "        x = self.conv5(x, edge_index)\n",
    "        x  = self.b5(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = self.drop_5(x,drop_en)\n",
    "        \n",
    "        x_5 = global_mean_pool(x, batch)\n",
    "        \n",
    "        x = self.conv6(x, edge_index)\n",
    "        x  = self.b6(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = self.drop_6(x,drop_en)\n",
    "        \n",
    "        x = self.conv7(x, edge_index)\n",
    "        x  = self.b7(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        \n",
    "        x = self.conv8(x, edge_index)\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "        \n",
    "        x = torch.stack([x,x_1,x_5,x_3],dim=2)\n",
    "        \n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        \n",
    "        #x = torch.unsqueeze(x,2)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        x = self.lin(x)\n",
    "        \n",
    "        x = m(x)\n",
    "        \n",
    "        \n",
    "        node_class_hidden = self.conv1_node_class(dicriminator,edge_index)\n",
    "        node_class_hidden = node_class_hidden.relu()\n",
    "        \n",
    "        node_class_hidden = self.conv2_node_class(node_class_hidden,edge_index)\n",
    "        node_class_hidden = node_class_hidden.relu()\n",
    "        \n",
    "        #print(index_arr.shape , node_class_hidden.shape)\n",
    "        \n",
    "        node_class_hidden = node_class_hidden[index_arr]\n",
    "        \n",
    "        #print(node_class_hidden.shape)\n",
    "        node_class_hidden = torch.unsqueeze(node_class_hidden, dim=2)\n",
    "        \n",
    "        node_pre = self.lin_node_class(node_class_hidden)\n",
    "        \n",
    "            \n",
    "        #print(\"hiiii :\" , dicriminator.shape)\n",
    "        dis_invariant = self.dis(dicriminator,edge_index,batch,drop_en)\n",
    "        \n",
    "        return x ,dis_invariant ,node_pre\n",
    "\n",
    "model = GCN(hidden_channels=128).to(device)\n",
    "print(model)\n",
    "\n",
    "def check_folder(log_dir):\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    return log_dir\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion= FocalLoss(gamma=2)\n",
    "criterion_node_class=  torch.nn.CrossEntropyLoss()\n",
    "criterion_2 = FocalLoss(gamma=2)\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    losses_adv_loss=0\n",
    "    losses_loss_cls=0\n",
    "    total_loss = 0\n",
    "    losses_node_cls_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}', unit='batch')\n",
    "    for graph in progress_bar:  # Iterate in batches over the training dataset.\n",
    "        graph = graph.to(device)  # Move data to the device\n",
    "        \n",
    "        drop_en = bool(np.random.binomial(1, 0.5))\n",
    "        \n",
    "        if graph.x.shape[0] < 29952 :\n",
    "            \n",
    "            if graph.x.shape[0] < 64:\n",
    "            \n",
    "                index_arr = torch.randint(0, int(graph.x.shape[0]), (int(graph.x.shape[0]),)).to(device)\n",
    "            else :\n",
    "                \n",
    "                index_arr = torch.randint(0, int(graph.x.shape[0]), (64,)).to(device)\n",
    "        else :\n",
    "                \n",
    "            index_arr = torch.randint(0, 29952, (64,)).to(device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        out,domain_invariant,node_pre = model(graph.x, graph.edge_index, graph.batch,drop_en,index_arr)  # Perform a single forward pass.\n",
    "        \n",
    "        adv_loss = criterion_2(domain_invariant, graph.data)\n",
    "        \n",
    "        node_cls_loss = criterion_node_class(node_pre.squeeze(),graph.y_node.float()[index_arr])\n",
    "        #print(out.shape , graph.y.long().shape)\n",
    "        loss_cls = criterion(out.squeeze(), graph.y)  # Compute the loss.\n",
    "        \n",
    "        loss_all = adv_loss + loss_cls + node_cls_loss\n",
    "        loss_all.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "        total_loss = loss_all + total_loss\n",
    "        losses_adv_loss = adv_loss + losses_adv_loss\n",
    "        losses_loss_cls = loss_cls + losses_loss_cls\n",
    "        losses_node_cls_loss = node_cls_loss + losses_node_cls_loss\n",
    "\n",
    "\n",
    "    print(\"/////////////////////////\")\n",
    "    print(\"adverserial loss : \" ,losses_adv_loss/len(train_loader.dataset))  \n",
    "    print(\"classification loss : \" , losses_loss_cls/len(train_loader.dataset))\n",
    "    print(\"classification node loss : \" , losses_node_cls_loss/len(train_loader.dataset))\n",
    "    print(\"total loss : \" ,total_loss/len(train_loader.dataset) )\n",
    "    print(\"////////////////////////////////////\")\n",
    "def test(loader,epoch):\n",
    "    score_path = os.path.join(\"/home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores\", \"epoch_{}\".format(epoch+1))\n",
    "    check_folder(score_path)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        scores_list = []\n",
    "\n",
    "        correct = 0\n",
    "        s= 0\n",
    "        progress_bar = tqdm(loader, desc=f'Epoch {epoch+1}', unit='batch')\n",
    "        for graph in progress_bar:  # Iterate in batches over the training/test dataset.\n",
    "            if graph.x.shape[0] < 29952 :\n",
    "\n",
    "                if graph.x.shape[0] < 64:\n",
    "\n",
    "                    index_arr = torch.randint(0, int(graph.x.shape[0]), (int(graph.x.shape[0]),)).to(device)\n",
    "                else :\n",
    "\n",
    "                    index_arr = torch.randint(0, int(graph.x.shape[0]), (64,)).to(device)\n",
    "            else :\n",
    "\n",
    "                index_arr = torch.randint(0, 29952, (64,)).to(device)\n",
    "                \n",
    "            graph = graph.to(device)  # Move data to the device\n",
    "            logit,_ ,_= model(graph.x, graph.edge_index, graph.batch,False,index_arr)\n",
    "            logit = logit[:,1]\n",
    "            live_label = graph.y.float()\n",
    "            for i in range(len(logit)):\n",
    "                        scores_list.append(\"{} {}\\n\".format(logit[i].item(), live_label[i].item()))\n",
    "  # Check against ground-truth labels.\n",
    "    map_score_val_filename = os.path.join(score_path, \"score.txt\")\n",
    "    with open(map_score_val_filename, 'w') as file:\n",
    "                file.writelines(scores_list)\n",
    "    print(\"score: write test scores to {}\".format(map_score_val_filename))\n",
    "    test_ACC, fpr, FRR, HTER, auc_test, test_err, tpr = performances_val(map_score_val_filename)\n",
    "    print(\"epoch:{:d}, test:  val_ACC={:.4f}, HTER={:.4f}, AUC={:.4f}, val_err={:.4f}, ACC={:.4f}, TPR={:.4f}\".format(\n",
    "        epoch + 1, test_ACC, HTER, auc_test, test_err, test_ACC, tpr))  \n",
    "    return auc_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95962055",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████████████████████| 1560/1560 [03:45<00:00,  6.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████████████████████| 2131/2131 [04:33<00:00,  7.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_11/score.txt\n",
      "epoch:11, test:  val_ACC=0.7745, HTER=0.2255, AUC=0.8522, val_err=0.2255, ACC=0.7745, TPR=0.3290\n",
      "improve acc .. .. ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████████████████████| 1560/1560 [03:47<00:00,  6.85batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(5.7485e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(3.6906e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████████████████████| 2131/2131 [04:36<00:00,  7.71batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_12/score.txt\n",
      "epoch:12, test:  val_ACC=0.8535, HTER=0.1465, AUC=0.9278, val_err=0.1465, ACC=0.8535, TPR=0.6156\n",
      "improve acc .. .. ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████████████████████| 1560/1560 [03:48<00:00,  6.82batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(3.6403e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(2.7893e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████████████████████| 2131/2131 [05:55<00:00,  6.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_13/score.txt\n",
      "epoch:13, test:  val_ACC=0.7812, HTER=0.2188, AUC=0.8669, val_err=0.2188, ACC=0.7812, TPR=0.4583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████████████████████| 1560/1560 [03:49<00:00,  6.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(3.2413e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(2.3192e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████████████████████| 2131/2131 [04:58<00:00,  7.14batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_14/score.txt\n",
      "epoch:14, test:  val_ACC=0.8431, HTER=0.1569, AUC=0.9150, val_err=0.1569, ACC=0.8431, TPR=0.5787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████████████████████| 1560/1560 [10:58<00:00,  2.37batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(3.3497e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.8182e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████████████████████| 2131/2131 [08:09<00:00,  4.36batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_15/score.txt\n",
      "epoch:15, test:  val_ACC=0.7865, HTER=0.2135, AUC=0.8721, val_err=0.2135, ACC=0.7865, TPR=0.4541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████████████████████| 1560/1560 [03:49<00:00,  6.80batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.9734e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.3449e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████████████████████| 2131/2131 [04:42<00:00,  7.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_16/score.txt\n",
      "epoch:16, test:  val_ACC=0.8310, HTER=0.1698, AUC=0.8955, val_err=0.1694, ACC=0.8310, TPR=0.4242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████████████████████| 1560/1560 [03:47<00:00,  6.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.0443e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.3723e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████████████████████| 2131/2131 [04:38<00:00,  7.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_17/score.txt\n",
      "epoch:17, test:  val_ACC=0.8081, HTER=0.1919, AUC=0.8919, val_err=0.1920, ACC=0.8081, TPR=0.5001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████████████████████| 1560/1560 [03:47<00:00,  6.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.8390e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.0731e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████████████████████| 2131/2131 [05:41<00:00,  6.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_18/score.txt\n",
      "epoch:18, test:  val_ACC=0.8398, HTER=0.1604, AUC=0.9156, val_err=0.1603, ACC=0.8398, TPR=0.5485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████████████████████| 1560/1560 [10:43<00:00,  2.43batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.4298e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.3178e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████████████████████| 2131/2131 [12:26<00:00,  2.85batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_19/score.txt\n",
      "epoch:19, test:  val_ACC=0.8177, HTER=0.1823, AUC=0.8990, val_err=0.1823, ACC=0.8177, TPR=0.5256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████████████████████| 1560/1560 [09:29<00:00,  2.74batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(7.4350e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(1.1201e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████████████████████| 2131/2131 [13:55<00:00,  2.55batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_20/score.txt\n",
      "epoch:20, test:  val_ACC=0.8372, HTER=0.1628, AUC=0.9177, val_err=0.1628, ACC=0.8372, TPR=0.5589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████████████████████| 1560/1560 [09:23<00:00,  2.77batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(8.1624e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(9.9483e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████████████████████| 2131/2131 [12:12<00:00,  2.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: write test scores to /home/hassan-hossein/single_image_graph_face_anti_spoofing/train/Scores/epoch_21/score.txt\n",
      "epoch:21, test:  val_ACC=0.8914, HTER=0.1086, AUC=0.9520, val_err=0.1086, ACC=0.8914, TPR=0.7110\n",
      "improve acc .. .. ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████████████████████| 1560/1560 [11:03<00:00,  2.35batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////\n",
      "adverserial loss :  tensor(1.0530e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification loss :  tensor(9.6544e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "classification node loss :  tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total loss :  tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "////////////////////////////////////\n",
      "***************************\n",
      "test : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22:  75%|███████████████████▌      | 1600/2131 [08:58<02:58,  2.97batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#print(\"train : \")\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#train_auc = test(train_loader,epoch)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest : \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m test_auc \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_auc \u001b[38;5;241m>\u001b[39m best_auc:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimprove acc .. .. ..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(loader, epoch)\u001b[0m\n\u001b[1;32m    288\u001b[0m s\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    289\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m tqdm(loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 290\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m graph \u001b[38;5;129;01min\u001b[39;00m progress_bar:  \u001b[38;5;66;03m# Iterate in batches over the training/test dataset.\u001b[39;00m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m29952\u001b[39m :\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m64\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1359\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1362\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1325\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1325\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1326\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1327\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    106\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/anaconda3/envs/Wav2Lip/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(\"Focal_without_pipline_domain_generalization_tuning_for_I.pth\",map_location='cuda'))\n",
    "\n",
    "# best_auc = 0.9391\n",
    "best_auc = 0\n",
    "for epoch in range(10, 1000):\n",
    "    train(epoch)\n",
    "    print(\"***************************\")\n",
    "    #print(\"train : \")\n",
    "    #train_auc = test(train_loader,epoch)\n",
    "    print(\"test : \")\n",
    "    test_auc = test(test_loader,epoch)\n",
    "    if test_auc > best_auc:\n",
    "        print(\"improve acc .. .. ..\")\n",
    "        torch.save(model.state_dict(), 'Focal_without_pipline_domain_generalization_tuning_for_I_2.pth')\n",
    "        best_auc = test_auc\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969be31f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f266fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Wav2Lip)",
   "language": "python",
   "name": "wav2lip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
